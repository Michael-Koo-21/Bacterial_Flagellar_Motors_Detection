{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ddddf23",
   "metadata": {
    "papermill": {
     "duration": 0.003603,
     "end_time": "2025-05-07T16:15:55.215429",
     "exception": false,
     "start_time": "2025-05-07T16:15:55.211826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BYU Locating Flagellar Motors - Submission Notebook\n",
    "\n",
    "This submission notebook processes test tomograms to locate bacterial flagellar motors using an ensemble approach combining 2D YOLOv8 detection and 3D CNN validation. The approach consists of:\n",
    "\n",
    "1. Loading pre-trained models (YOLOv8 and 3D CNN)\n",
    "2. Processing each tomogram slice-by-slice\n",
    "3. Finding potential motor candidates using YOLOv8\n",
    "4. Validating candidates with a 3D CNN model\n",
    "5. Generating the final submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6220f0e8",
   "metadata": {
    "papermill": {
     "duration": 0.002496,
     "end_time": "2025-05-07T16:15:55.220976",
     "exception": false,
     "start_time": "2025-05-07T16:15:55.218480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24af8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T16:15:55.227752Z",
     "iopub.status.busy": "2025-05-07T16:15:55.227053Z",
     "iopub.status.idle": "2025-05-07T16:15:58.575933Z",
     "shell.execute_reply": "2025-05-07T16:15:58.575146Z"
    },
    "papermill": {
     "duration": 3.353721,
     "end_time": "2025-05-07T16:15:58.577356",
     "exception": false,
     "start_time": "2025-05-07T16:15:55.223635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required packages from offline sources\n",
    "import kagglehub\n",
    "kagglehub.dataset_download('michaelkoo21/flagellar-motor-model-2')\n",
    "kagglehub.dataset_download('rachiteagles/yolo-pkg')\n",
    "\n",
    "# Install the YOLO package from the downloaded wheel file\n",
    "!pip install --no-index --no-deps /kaggle/input/yolo-pkg/yolo/ultralytics-8.3.112-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ec9b2",
   "metadata": {
    "papermill": {
     "duration": 0.002678,
     "end_time": "2025-05-07T16:15:58.583456",
     "exception": false,
     "start_time": "2025-05-07T16:15:58.580778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e14e7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T16:15:58.590148Z",
     "iopub.status.busy": "2025-05-07T16:15:58.589800Z",
     "iopub.status.idle": "2025-05-07T16:16:08.453926Z",
     "shell.execute_reply": "2025-05-07T16:16:08.453342Z"
    },
    "papermill": {
     "duration": 9.869076,
     "end_time": "2025-05-07T16:16:08.455313",
     "exception": false,
     "start_time": "2025-05-07T16:15:58.586237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import yaml\n",
    "import random\n",
    "import time\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "from contextlib import nullcontext\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "# Define paths for Kaggle environment\n",
    "DATA_DIR = '/kaggle/input/byu-locating-bacterial-flagellar-motors-2025'\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
    "MODEL_DIR = '/kaggle/input/michaelkoo21-flagellar-motor-model-2'\n",
    "SUBMISSION_PATH = '/kaggle/working/submission.csv'\n",
    "WORKING_DIR = '/kaggle/working'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0733199",
   "metadata": {
    "papermill": {
     "duration": 0.003827,
     "end_time": "2025-05-07T16:16:08.462321",
     "exception": false,
     "start_time": "2025-05-07T16:16:08.458494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3D CNN Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75390bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T16:16:08.469015Z",
     "iopub.status.busy": "2025-05-07T16:16:08.468650Z",
     "iopub.status.idle": "2025-05-07T16:16:08.480810Z",
     "shell.execute_reply": "2025-05-07T16:16:08.480311Z"
    },
    "papermill": {
     "duration": 0.016576,
     "end_time": "2025-05-07T16:16:08.481747",
     "exception": false,
     "start_time": "2025-05-07T16:16:08.465171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionBlock(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    3D attention block for focusing on motor-specific features\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels):\n",
    "        \"\"\"\n",
    "        Initialize the attention block\n",
    "        \n",
    "        Args:\n",
    "            in_channels (int): Number of input channels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.query = torch.nn.Conv3d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.key = torch.nn.Conv3d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.value = torch.nn.Conv3d(in_channels, in_channels, kernel_size=1)\n",
    "        self.gamma = torch.nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the attention block\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with attention applied\n",
    "        \"\"\"\n",
    "        batch_size, channels, depth, height, width = x.size()\n",
    "        \n",
    "        # Reshape for attention calculation\n",
    "        query = self.query(x).view(batch_size, -1, depth * height * width).permute(0, 2, 1)\n",
    "        key = self.key(x).view(batch_size, -1, depth * height * width)\n",
    "        value = self.value(x).view(batch_size, -1, depth * height * width)\n",
    "        \n",
    "        # Calculate attention\n",
    "        attention = torch.bmm(query, key)\n",
    "        attention = self.softmax(attention)\n",
    "        \n",
    "        # Apply attention\n",
    "        out = torch.bmm(value, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch_size, channels, depth, height, width)\n",
    "        \n",
    "        # Residual connection\n",
    "        out = self.gamma * out + x\n",
    "        return out\n",
    "\n",
    "class Motor3DCNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    3D CNN for detecting flagellar motors in tomogram volumes\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels=1, dropout_rate=0.3):\n",
    "        \"\"\"\n",
    "        Initialize the 3D CNN model\n",
    "        \n",
    "        Args:\n",
    "            input_channels (int): Number of input channels\n",
    "            dropout_rate (float): Dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initial convolution layers\n",
    "        self.conv1 = torch.nn.Conv3d(input_channels, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm3d(16)\n",
    "        self.conv2 = torch.nn.Conv3d(16, 32, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn2 = torch.nn.BatchNorm3d(32)\n",
    "        self.conv3 = torch.nn.Conv3d(32, 64, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn3 = torch.nn.BatchNorm3d(64)\n",
    "        self.conv4 = torch.nn.Conv3d(64, 128, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn4 = torch.nn.BatchNorm3d(128)\n",
    "        \n",
    "        # Attention block\n",
    "        self.attention = AttentionBlock(128)\n",
    "        \n",
    "        # Global average pooling\n",
    "        self.global_avg_pool = torch.nn.AdaptiveAvgPool3d(1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = torch.nn.Linear(128, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)  # Binary classification: motor presence\n",
    "        \n",
    "        # Regression head for 3D coordinates\n",
    "        self.reg = torch.nn.Linear(32, 3)\n",
    "        \n",
    "        # Activation and dropout\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the 3D CNN\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (Classification output, Regression output)\n",
    "        \"\"\"\n",
    "        # Initial convolutions\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        \n",
    "        # Apply attention\n",
    "        x = self.attention(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Classification output\n",
    "        cls_output = self.sigmoid(self.fc3(x))\n",
    "        \n",
    "        # Regression output (normalized coordinates)\n",
    "        reg_output = self.reg(x)\n",
    "        \n",
    "        return cls_output, reg_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf704eb",
   "metadata": {
    "papermill": {
     "duration": 0.002713,
     "end_time": "2025-05-07T16:16:08.487340",
     "exception": false,
     "start_time": "2025-05-07T16:16:08.484627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Image Processing and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa5c011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T16:16:08.494381Z",
     "iopub.status.busy": "2025-05-07T16:16:08.493749Z",
     "iopub.status.idle": "2025-05-07T16:16:08.500402Z",
     "shell.execute_reply": "2025-05-07T16:16:08.499849Z"
    },
    "papermill": {
     "duration": 0.011122,
     "end_time": "2025-05-07T16:16:08.501374",
     "exception": false,
     "start_time": "2025-05-07T16:16:08.490252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    \"\"\"\n",
    "    Class for processing and normalizing tomogram slices.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def normalize_slice(img_array, method='adaptive'):\n",
    "        \"\"\"\n",
    "        Normalize slice using different normalization methods\n",
    "        \n",
    "        Args:\n",
    "            img_array (np.ndarray): Input image array\n",
    "            method (str): Normalization method ('percentile', 'histogram', 'adaptive')\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Normalized image\n",
    "        \"\"\"\n",
    "        if method == 'percentile':\n",
    "            # Percentile-based normalization (2nd to 98th percentile)\n",
    "            p2 = np.percentile(img_array, 2)\n",
    "            p98 = np.percentile(img_array, 98)\n",
    "            normalized = np.clip(img_array, p2, p98)\n",
    "            normalized = 255 * (normalized - p2) / (p98 - p2)\n",
    "            return np.uint8(normalized)\n",
    "        \n",
    "        elif method == 'histogram':\n",
    "            # Histogram equalization\n",
    "            return cv2.equalizeHist(img_array)\n",
    "        \n",
    "        elif method == 'adaptive':\n",
    "            # Combination of methods\n",
    "            # First apply percentile normalization\n",
    "            p2 = np.percentile(img_array, 2)\n",
    "            p98 = np.percentile(img_array, 98)\n",
    "            normalized = np.clip(img_array, p2, p98)\n",
    "            normalized = 255 * (normalized - p2) / (p98 - p2)\n",
    "            normalized = np.uint8(normalized)\n",
    "            \n",
    "            # Then apply adaptive histogram equalization\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            return clahe.apply(normalized)\n",
    "        \n",
    "        else:\n",
    "            return img_array\n",
    "\n",
    "# GPU profiling context manager\n",
    "class GPUProfiler:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.start_time = None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        self.start_time = time.time()\n",
    "        return self\n",
    "        \n",
    "    def __exit__(self, *args):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        elapsed = time.time() - self.start_time\n",
    "        print(f\"[PROFILE] {self.name}: {elapsed:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e82992",
   "metadata": {
    "papermill": {
     "duration": 0.002661,
     "end_time": "2025-05-07T16:16:08.506863",
     "exception": false,
     "start_time": "2025-05-07T16:16:08.504202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ensemble Motor Detector Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e173e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T16:16:08.514494Z",
     "iopub.status.busy": "2025-05-07T16:16:08.514312Z",
     "iopub.status.idle": "2025-05-07T16:16:08.548928Z",
     "shell.execute_reply": "2025-05-07T16:16:08.548399Z"
    },
    "papermill": {
     "duration": 0.039746,
     "end_time": "2025-05-07T16:16:08.549996",
     "exception": false,
     "start_time": "2025-05-07T16:16:08.510250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EnsembleMotorDetector:\n",
    "    \"\"\"\n",
    "    Ensemble detector combining 2D YOLOv8 and 3D CNN for improved motor detection\n",
    "    \"\"\"\n",
    "    def __init__(self, yolo_model_path, cnn3d_model_path, test_dir, submission_path, \n",
    "                 device='auto', yolo_confidence_threshold=0.30, cnn_confidence_threshold=0.45):\n",
    "        \"\"\"\n",
    "        Initialize the detector with both YOLO and 3D CNN models\n",
    "        \n",
    "        Args:\n",
    "            yolo_model_path (str): Path to trained YOLO model weights\n",
    "            cnn3d_model_path (str): Path to trained 3D CNN model weights\n",
    "            test_dir (str): Path to test tomograms directory\n",
    "            submission_path (str): Path to save submission CSV\n",
    "            device (str): Device to use ('cpu', 'cuda', or 'auto')\n",
    "            yolo_confidence_threshold (float): Confidence threshold for YOLO detections\n",
    "            cnn_confidence_threshold (float): Confidence threshold for 3D CNN detections\n",
    "        \"\"\"\n",
    "        self.yolo_model_path = yolo_model_path\n",
    "        self.cnn3d_model_path = cnn3d_model_path\n",
    "        self.test_dir = test_dir\n",
    "        self.submission_path = submission_path\n",
    "        self.yolo_confidence_threshold = yolo_confidence_threshold\n",
    "        self.cnn_confidence_threshold = cnn_confidence_threshold\n",
    "        \n",
    "        # Set device\n",
    "        if device == 'auto':\n",
    "            self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "            \n",
    "        print(f\"Using device: {self.device} for ensemble detection\")\n",
    "        \n",
    "        # Detection parameters\n",
    "        self.nms_iou_threshold = 0.2  # Non-maximum suppression threshold\n",
    "        self.batch_size = 8  # Default batch size, will be adjusted dynamically\n",
    "        self.concentration = 1.0  # Process all slices (can be reduced for faster testing)\n",
    "        self.subvolume_size = 64  # Size of 3D CNN input subvolumes\n",
    "    \n",
    "    def load_models(self):\n",
    "        \"\"\"\n",
    "        Load both YOLO and 3D CNN models\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (YOLO model, 3D CNN model)\n",
    "        \"\"\"\n",
    "        # Load YOLO model\n",
    "        print(f\"Loading YOLO model from {self.yolo_model_path}\")\n",
    "        yolo_model = YOLO(self.yolo_model_path)\n",
    "        yolo_model.to(self.device)\n",
    "        \n",
    "        # Fuse layers for faster inference if using GPU\n",
    "        if self.device.startswith('cuda'):\n",
    "            yolo_model.fuse()\n",
    "            \n",
    "            # Use half precision if on compatible GPU\n",
    "            if torch.cuda.get_device_capability(0)[0] >= 7:  # Volta or newer\n",
    "                yolo_model.model.half()\n",
    "                print(\"Using half precision (FP16) for YOLO inference\")\n",
    "                \n",
    "            # Get available GPU memory and set batch size accordingly\n",
    "            free_mem = torch.cuda.get_device_properties(0).total_memory / 1e9 - torch.cuda.memory_allocated(0) / 1e9\n",
    "            self.batch_size = max(4, min(32, int(free_mem * 4)))  # 4 images per GB as rough estimate\n",
    "            print(f\"Dynamic batch size set to {self.batch_size} based on available GPU memory\")\n",
    "        \n",
    "        # Load 3D CNN model\n",
    "        print(f\"Loading 3D CNN model from {self.cnn3d_model_path}\")\n",
    "        cnn3d_model = Motor3DCNN(input_channels=1, dropout_rate=0.0)  # No dropout for inference\n",
    "        cnn3d_model.load_state_dict(torch.load(self.cnn3d_model_path, map_location=self.device))\n",
    "        cnn3d_model.to(self.device)\n",
    "        cnn3d_model.eval()  # Set to evaluation mode\n",
    "        \n",
    "        return yolo_model, cnn3d_model\n",
    "    \n",
    "    def preload_image_batch(self, file_paths):\n",
    "        \"\"\"\n",
    "        Preload a batch of images to CPU memory\n",
    "        \n",
    "        Args:\n",
    "            file_paths (list): List of file paths to load\n",
    "            \n",
    "        Returns:\n",
    "            list: List of loaded images\n",
    "        \"\"\"\n",
    "        images = []\n",
    "        for path in file_paths:\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                # Try with PIL as fallback\n",
    "                img = np.array(Image.open(path))\n",
    "            images.append(img)\n",
    "        return images\n",
    "    \n",
    "    def perform_3d_nms(self, detections, iou_threshold):\n",
    "        \"\"\"\n",
    "        Perform 3D Non-Maximum Suppression on detections\n",
    "        \n",
    "        Args:\n",
    "            detections (list): List of detection dictionaries\n",
    "            iou_threshold (float): IoU threshold for suppression\n",
    "            \n",
    "        Returns:\n",
    "            list: Filtered detections after NMS\n",
    "        \"\"\"\n",
    "        if not detections:\n",
    "            return []\n",
    "        \n",
    "        # Sort by confidence (highest first)\n",
    "        detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n",
    "        \n",
    "        # List to store final detections after NMS\n",
    "        final_detections = []\n",
    "        \n",
    "        # Define 3D distance function\n",
    "        def distance_3d(d1, d2):\n",
    "            return np.sqrt((d1['z'] - d2['z'])**2 + \n",
    "                          (d1['y'] - d2['y'])**2 + \n",
    "                          (d1['x'] - d2['x'])**2)\n",
    "        \n",
    "        # Maximum distance threshold (based on box size)\n",
    "        box_size = 24  # Same as annotation box size\n",
    "        distance_threshold = box_size * iou_threshold\n",
    "        \n",
    "        # Process each detection\n",
    "        while detections:\n",
    "            # Take the detection with highest confidence\n",
    "            best_detection = detections.pop(0)\n",
    "            final_detections.append(best_detection)\n",
    "            \n",
    "            # Filter out detections that are too close to the best detection\n",
    "            detections = [d for d in detections if distance_3d(d, best_detection) > distance_threshold]\n",
    "        \n",
    "        return final_detections\n",
    "    \n",
    "    def extract_subvolume(self, tomo_id, z, y, x):\n",
    "        \"\"\"\n",
    "        Extract a subvolume centered at the given coordinates\n",
    "        \n",
    "        Args:\n",
    "            tomo_id (str): Tomogram ID\n",
    "            z (int): Z coordinate\n",
    "            y (int): Y coordinate\n",
    "            x (int): X coordinate\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Extracted subvolume as a tensor with shape [1, 1, D, H, W]\n",
    "        \"\"\"\n",
    "        half_size = self.subvolume_size // 2\n",
    "        subvolume = np.zeros((self.subvolume_size, self.subvolume_size, self.subvolume_size), dtype=np.float32)\n",
    "        tomo_dir = os.path.join(self.test_dir, tomo_id)\n",
    "        \n",
    "        # Load the slices\n",
    "        for i, z_pos in enumerate(range(z - half_size, z + half_size)):\n",
    "            if z_pos < 0:\n",
    "                continue\n",
    "                \n",
    "            slice_path = os.path.join(tomo_dir, f\"slice_{z_pos:04d}.jpg\")\n",
    "            if not os.path.exists(slice_path):\n",
    "                continue\n",
    "                \n",
    "            # Load and normalize slice\n",
    "            img = np.array(Image.open(slice_path))\n",
    "            \n",
    "            # Normalize using our adaptive method\n",
    "            p2 = np.percentile(img, 2)\n",
    "            p98 = np.percentile(img, 98)\n",
    "            normalized = np.clip(img, p2, p98)\n",
    "            normalized = (normalized - p2) / (p98 - p2)\n",
    "            \n",
    "            # Convert to float32 for processing\n",
    "            normalized = normalized.astype(np.float32)\n",
    "            \n",
    "            # Extract region around center\n",
    "            y_start = max(0, y - half_size)\n",
    "            y_end = min(img.shape[0], y + half_size)\n",
    "            x_start = max(0, x - half_size)\n",
    "            x_end = min(img.shape[1], x + half_size)\n",
    "            \n",
    "            # Calculate target indices in subvolume\n",
    "            target_i = i\n",
    "            target_y_start = max(0, half_size - (y - y_start))\n",
    "            target_x_start = max(0, half_size - (x - x_start))\n",
    "            \n",
    "            # Calculate amount to copy\n",
    "            height = min(y_end - y_start, self.subvolume_size - target_y_start)\n",
    "            width = min(x_end - x_start, self.subvolume_size - target_x_start)\n",
    "            \n",
    "            if height <= 0 or width <= 0:\n",
    "                continue\n",
    "                \n",
    "            # Copy data\n",
    "            subvolume[target_i, \n",
    "                     target_y_start:target_y_start+height, \n",
    "                     target_x_start:target_x_start+width] = normalized[y_start:y_start+height, \n",
    "                                                                      x_start:x_start+width]\n",
    "        \n",
    "        # Add batch and channel dimensions to create a 5D tensor [B, C, D, H, W]\n",
    "        # This is the fix for the \"expected 5D input (got 4D input)\" error\n",
    "        subvolume_tensor = torch.tensor(subvolume).float()\n",
    "        subvolume_tensor = subvolume_tensor.unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n",
    "        \n",
    "        return subvolume_tensor\n",
    "    \n",
    "    def process_tomogram(self, tomo_id, yolo_model, cnn3d_model, index=0, total=1):\n",
    "        \"\"\"\n",
    "        Process a single tomogram using both YOLO and 3D CNN models\n",
    "        \n",
    "        Args:\n",
    "            tomo_id (str): Tomogram ID\n",
    "            yolo_model: YOLO model\n",
    "            cnn3d_model: 3D CNN model\n",
    "            index (int): Current tomogram index\n",
    "            total (int): Total number of tomograms\n",
    "            \n",
    "        Returns:\n",
    "            dict: Detection result with coordinates\n",
    "        \"\"\"\n",
    "        print(f\"Processing tomogram {tomo_id} ({index}/{total})\")\n",
    "        \n",
    "        # Get all slice files for this tomogram\n",
    "        tomo_dir = os.path.join(self.test_dir, tomo_id)\n",
    "        slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
    "        \n",
    "        # Apply concentration if needed\n",
    "        if self.concentration < 1.0:\n",
    "            selected_indices = np.linspace(0, len(slice_files)-1, int(len(slice_files) * self.concentration))\n",
    "            selected_indices = np.round(selected_indices).astype(int)\n",
    "            slice_files = [slice_files[i] for i in selected_indices]\n",
    "            print(f\"Processing {len(slice_files)} out of {len(os.listdir(tomo_dir))} slices\")\n",
    "        \n",
    "        # STEP 1: Run YOLO on 2D slices to get candidates\n",
    "        print(\"STEP 1: Running YOLO detection on 2D slices...\")\n",
    "        yolo_detections = []\n",
    "        \n",
    "        # Create CUDA streams for parallel processing\n",
    "        if self.device.startswith('cuda'):\n",
    "            streams = [torch.cuda.Stream() for _ in range(min(4, self.batch_size))]\n",
    "        else:\n",
    "            streams = [None]\n",
    "        \n",
    "        # Variables for preloading\n",
    "        next_batch_thread = None\n",
    "        next_batch_images = None\n",
    "        \n",
    "        # Process slices in batches\n",
    "        for batch_start in range(0, len(slice_files), self.batch_size):\n",
    "            # Wait for previous preload thread if it exists\n",
    "            if next_batch_thread is not None:\n",
    "                next_batch_thread.join()\n",
    "                next_batch_images = None\n",
    "                \n",
    "            batch_end = min(batch_start + self.batch_size, len(slice_files))\n",
    "            batch_files = slice_files[batch_start:batch_end]\n",
    "            \n",
    "            # Start preloading next batch\n",
    "            next_batch_start = batch_end\n",
    "            next_batch_end = min(next_batch_start + self.batch_size, len(slice_files))\n",
    "            next_batch_files = slice_files[next_batch_start:next_batch_end] if next_batch_start < len(slice_files) else []\n",
    "            \n",
    "            if next_batch_files:\n",
    "                next_batch_paths = [os.path.join(tomo_dir, f) for f in next_batch_files]\n",
    "                next_batch_thread = threading.Thread(target=self.preload_image_batch, args=(next_batch_paths,))\n",
    "                next_batch_thread.start()\n",
    "            else:\n",
    "                next_batch_thread = None\n",
    "            \n",
    "            # Split batch across streams for parallel processing\n",
    "            sub_batches = np.array_split(batch_files, len(streams))\n",
    "            \n",
    "            for i, sub_batch in enumerate(sub_batches):\n",
    "                if len(sub_batch) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                stream = streams[i % len(streams)]\n",
    "                with torch.cuda.stream(stream) if stream and self.device.startswith('cuda') else nullcontext():\n",
    "                    # Process sub-batch\n",
    "                    sub_batch_paths = [os.path.join(tomo_dir, slice_file) for slice_file in sub_batch]\n",
    "                    sub_batch_slice_nums = [int(slice_file.split('_')[1].split('.')[0]) for slice_file in sub_batch]\n",
    "                    \n",
    "                    # Run inference\n",
    "                    sub_results = yolo_model(sub_batch_paths, verbose=False)\n",
    "                    \n",
    "                    # Process each result in this sub-batch\n",
    "                    for j, result in enumerate(sub_results):\n",
    "                        if len(result.boxes) > 0:\n",
    "                            boxes = result.boxes\n",
    "                            for box_idx, confidence in enumerate(boxes.conf):\n",
    "                                if confidence >= self.yolo_confidence_threshold:\n",
    "                                    # Get bounding box coordinates\n",
    "                                    x1, y1, x2, y2 = boxes.xyxy[box_idx].cpu().numpy()\n",
    "                                    \n",
    "                                    # Calculate center coordinates\n",
    "                                    x_center = (x1 + x2) / 2\n",
    "                                    y_center = (y1 + y2) / 2\n",
    "                                    \n",
    "                                    # Store detection with 3D coordinates\n",
    "                                    yolo_detections.append({\n",
    "                                        'z': round(sub_batch_slice_nums[j]),\n",
    "                                        'y': round(y_center),\n",
    "                                        'x': round(x_center),\n",
    "                                        'confidence': float(confidence),\n",
    "                                        'model': 'yolo'\n",
    "                                    })\n",
    "            \n",
    "            # Synchronize streams\n",
    "            if self.device.startswith('cuda'):\n",
    "                torch.cuda.synchronize()\n",
    "        \n",
    "        # Clean up thread if still running\n",
    "        if next_batch_thread is not None:\n",
    "            next_batch_thread.join()\n",
    "        \n",
    "        # Apply 3D NMS to consolidate YOLO detections\n",
    "        yolo_detections = self.perform_3d_nms(yolo_detections, self.nms_iou_threshold)\n",
    "        print(f\"YOLO found {len(yolo_detections)} potential candidates\")\n",
    "        \n",
    "        # If no YOLO detections, return early\n",
    "        if not yolo_detections:\n",
    "            return {\n",
    "                'tomo_id': tomo_id,\n",
    "                'Motor axis 0': -1,\n",
    "                'Motor axis 1': -1,\n",
    "                'Motor axis 2': -1\n",
    "            }\n",
    "        \n",
    "        # STEP 2: Validate candidates with 3D CNN\n",
    "        print(\"STEP 2: Validating candidates with 3D CNN...\")\n",
    "        validated_detections = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for detection in yolo_detections[:min(10, len(yolo_detections))]:  # Process top candidates\n",
    "                z, y, x = detection['z'], detection['y'], detection['x']\n",
    "                \n",
    "                # Skip if too close to edge for 3D CNN processing\n",
    "                half_size = self.subvolume_size // 2\n",
    "                slice_sample = os.path.join(tomo_dir, slice_files[0])\n",
    "                try:\n",
    "                    tomo_shape = np.array(Image.open(slice_sample)).shape\n",
    "                    if (z < half_size or z >= len(slice_files) - half_size or\n",
    "                        y < half_size or y >= tomo_shape[0] - half_size or\n",
    "                        x < half_size or x >= tomo_shape[1] - half_size):\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract subvolume with proper 5D shape [B, C, D, H, W]\n",
    "                    subvolume = self.extract_subvolume(tomo_id, z, y, x)\n",
    "                    subvolume = subvolume.to(self.device)\n",
    "                    \n",
    "                    # Run 3D CNN inference\n",
    "                    cls_output, reg_output = cnn3d_model(subvolume)\n",
    "                    \n",
    "                    # Check if 3D CNN confirms the detection\n",
    "                    if cls_output.item() >= self.cnn_confidence_threshold:\n",
    "                        # Add to validated detections\n",
    "                        validated_detections.append({\n",
    "                            'z': z,\n",
    "                            'y': y,\n",
    "                            'x': x,\n",
    "                            'yolo_confidence': detection['confidence'],\n",
    "                            'cnn_confidence': cls_output.item(),\n",
    "                            'ensemble_confidence': (detection['confidence'] + cls_output.item()) / 2,\n",
    "                            'model': 'ensemble'\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing candidate at z={z}, y={y}, x={x}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        print(f\"3D CNN validated {len(validated_detections)} candidates\")\n",
    "        \n",
    "        # STEP 3: Make final prediction using ensemble\n",
    "        if validated_detections:\n",
    "            # Sort by ensemble confidence\n",
    "            validated_detections.sort(key=lambda x: x['ensemble_confidence'], reverse=True)\n",
    "            best_detection = validated_detections[0]\n",
    "            \n",
    "            # Return the best ensemble detection\n",
    "            return {\n",
    "                'tomo_id': tomo_id,\n",
    "                'Motor axis 0': round(best_detection['z']),\n",
    "                'Motor axis 1': round(best_detection['y']),\n",
    "                'Motor axis 2': round(best_detection['x'])\n",
    "            }\n",
    "        else:\n",
    "            # If no validated detections, fall back to best YOLO detection\n",
    "            best_yolo = max(yolo_detections, key=lambda x: x['confidence'])\n",
    "            \n",
    "            # Only use YOLO if it's very confident\n",
    "            if best_yolo['confidence'] > 0.65:\n",
    "                return {\n",
    "                    'tomo_id': tomo_id,\n",
    "                    'Motor axis 0': round(best_yolo['z']),\n",
    "                    'Motor axis 1': round(best_yolo['y']),\n",
    "                    'Motor axis 2': round(best_yolo['x'])\n",
    "                }\n",
    "            else:\n",
    "                # Otherwise, say no motor found\n",
    "                return {\n",
    "                    'tomo_id': tomo_id,\n",
    "                    'Motor axis 0': -1,\n",
    "                    'Motor axis 1': -1,\n",
    "                    'Motor axis 2': -1\n",
    "                }\n",
    "    \n",
    "    def generate_submission(self):\n",
    "        \"\"\"\n",
    "        Process all test tomograms using the ensemble approach and generate submission\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Submission dataframe\n",
    "        \"\"\"\n",
    "        # Get list of test tomograms\n",
    "        test_tomos = sorted([d for d in os.listdir(self.test_dir) if os.path.isdir(os.path.join(self.test_dir, d))])\n",
    "        total_tomos = len(test_tomos)\n",
    "        \n",
    "        print(f\"Found {total_tomos} tomograms in test directory\")\n",
    "        \n",
    "        # Clear GPU cache before starting\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Load models\n",
    "        yolo_model, cnn3d_model = self.load_models()\n",
    "        \n",
    "        # Process tomograms with parallelization\n",
    "        results = []\n",
    "        motors_found = 0\n",
    "        \n",
    "        # Using ThreadPoolExecutor with max_workers=1 since each worker uses the GPU\n",
    "        # and we're parallelizing within each tomogram processing\n",
    "        with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "            future_to_tomo = {}\n",
    "            \n",
    "            # Submit all tomograms for processing\n",
    "            for i, tomo_id in enumerate(test_tomos, 1):\n",
    "                future = executor.submit(self.process_tomogram, tomo_id, yolo_model, cnn3d_model, i, total_tomos)\n",
    "                future_to_tomo[future] = tomo_id\n",
    "            \n",
    "            # Process completed futures as they complete\n",
    "            for future in future_to_tomo:\n",
    "                tomo_id = future_to_tomo[future]\n",
    "                try:\n",
    "                    # Clear CUDA cache between tomograms\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                    result = future.result()\n",
    "                    results.append(result)\n",
    "                    \n",
    "                    # Update motors found count\n",
    "                    motor_found = result['Motor axis 0'] != -1\n",
    "                    if motor_found:\n",
    "                        motors_found += 1\n",
    "                        print(f\"Motor found in {tomo_id} at position: \"\n",
    "                              f\"z={result['Motor axis 0']}, y={result['Motor axis 1']}, x={result['Motor axis 2']}\")\n",
    "                    else:\n",
    "                        print(f\"No motor detected in {tomo_id}\")\n",
    "                        \n",
    "                    print(f\"Current detection rate: {motors_found}/{len(results)} ({motors_found/len(results)*100:.1f}%)\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {tomo_id}: {e}\")\n",
    "                    # Create a default entry for failed tomograms\n",
    "                    results.append({\n",
    "                        'tomo_id': tomo_id,\n",
    "                        'Motor axis 0': -1,\n",
    "                        'Motor axis 1': -1,\n",
    "                        'Motor axis 2': -1\n",
    "                    })\n",
    "        \n",
    "        # Create submission dataframe\n",
    "        submission_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Ensure proper column order\n",
    "        submission_df = submission_df[['tomo_id', 'Motor axis 0', 'Motor axis 1', 'Motor axis 2']]\n",
    "        \n",
    "        # Save the submission file\n",
    "        submission_df.to_csv(self.submission_path, index=False)\n",
    "        \n",
    "        print(f\"\\nSubmission complete!\")\n",
    "        print(f\"Motors detected: {motors_found}/{total_tomos} ({motors_found/total_tomos*100:.1f}%)\")\n",
    "        print(f\"Submission saved to: {self.submission_path}\")\n",
    "        \n",
    "        # Display first few rows of submission\n",
    "        print(\"\\nSubmission preview:\")\n",
    "        print(submission_df.head())\n",
    "        \n",
    "        return submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928884bc",
   "metadata": {
    "papermill": {
     "duration": 0.002758,
     "end_time": "2025-05-07T16:16:08.555480",
     "exception": false,
     "start_time": "2025-05-07T16:16:08.552722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e672c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T16:16:08.562103Z",
     "iopub.status.busy": "2025-05-07T16:16:08.561855Z",
     "iopub.status.idle": "2025-05-07T16:17:31.621278Z",
     "shell.execute_reply": "2025-05-07T16:17:31.620339Z"
    },
    "papermill": {
     "duration": 83.064237,
     "end_time": "2025-05-07T16:17:31.622567",
     "exception": false,
     "start_time": "2025-05-07T16:16:08.558330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def debug_image_loading(test_dir):\n",
    "    \"\"\"\n",
    "    Debug function to check image loading for the first tomogram\n",
    "    \"\"\"\n",
    "    test_tomos = [d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))]\n",
    "    if not test_tomos:\n",
    "        print(\"No test tomograms found!\")\n",
    "        return\n",
    "        \n",
    "    tomo_id = test_tomos[0]\n",
    "    tomo_dir = os.path.join(test_dir, tomo_id)\n",
    "    slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
    "    \n",
    "    if not slice_files:\n",
    "        print(f\"No image files found in {tomo_dir}\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Found {len(slice_files)} image files in {tomo_dir}\")\n",
    "    sample_file = slice_files[len(slice_files)//2]  # Middle slice\n",
    "    img_path = os.path.join(tomo_dir, sample_file)\n",
    "    \n",
    "    # Try different loading methods\n",
    "    try:\n",
    "        # Method 1: PIL\n",
    "        img_pil = Image.open(img_path)\n",
    "        img_array_pil = np.array(img_pil)\n",
    "        print(f\"PIL Image shape: {img_array_pil.shape}, dtype: {img_array_pil.dtype}\")\n",
    "        \n",
    "        # Method 2: OpenCV\n",
    "        img_cv2 = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        print(f\"OpenCV Image shape: {img_cv2.shape}, dtype: {img_cv2.dtype}\")\n",
    "        \n",
    "        # Method 3: Convert to RGB\n",
    "        img_rgb = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "        print(f\"OpenCV RGB Image shape: {img_rgb.shape}, dtype: {img_rgb.dtype}\")\n",
    "        \n",
    "        print(\"Image loading successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {img_path}: {e}\")\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    # Verify test directory and image loading\n",
    "    print(\"Testing image loading...\")\n",
    "    debug_image_loading(TEST_DIR)\n",
    "    \n",
    "    # Define model paths\n",
    "    yolo_model_path = \"/kaggle/input/flagellar-motor-model-2/yolo_weights/motor_detector/weights/best.pt\"\n",
    "    cnn3d_model_path = \"/kaggle/input/flagellar-motor-model-2/3dcnn_models/3dcnn_best.pt\"\n",
    "    \n",
    "    # Create the ensemble motor detector\n",
    "    ensemble_detector = EnsembleMotorDetector(\n",
    "        yolo_model_path=yolo_model_path,\n",
    "        cnn3d_model_path=cnn3d_model_path,\n",
    "        test_dir=TEST_DIR,\n",
    "        submission_path=SUBMISSION_PATH,\n",
    "        device='auto',\n",
    "        yolo_confidence_threshold=0.30,  # Slightly lower threshold to catch more candidates\n",
    "        cnn_confidence_threshold=0.45    # Then filter with 3D CNN\n",
    "    )\n",
    "    \n",
    "    # Generate the ensemble submission\n",
    "    submission = ensemble_detector.generate_submission()\n",
    "    \n",
    "    return submission\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef5959",
   "metadata": {
    "papermill": {
     "duration": 0.003138,
     "end_time": "2025-05-07T16:17:31.629358",
     "exception": false,
     "start_time": "2025-05-07T16:17:31.626220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook implements a robust ensemble-based approach for detecting bacterial flagellar motors in cryo-ET tomograms. The main advantages of this approach are:\n",
    "\n",
    "1. Efficiency: Uses GPU optimization techniques like CUDA streams and batch processing\n",
    "2. Accuracy: Combines 2D YOLO detection with 3D CNN validation for better results\n",
    "3. Robustness: Handles variable tomogram sizes and poor signal-to-noise ratio\n",
    "4. Offline Operation: Works completely offline using pre-downloaded models\n",
    "\n",
    "The workflow follows these steps:\n",
    "\n",
    "1. Process each tomogram slice-by-slice with YOLO to identify potential motor locations\n",
    "2. Perform 3D non-maximum suppression to merge nearby detections\n",
    "3. Extract 3D subvolumes around candidate locations\n",
    "4. Validate candidates using the 3D CNN model\n",
    "5. Generate the final submission with motor coordinates or (-1, -1, -1) for tomograms without motors"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11294684,
     "sourceId": 91249,
     "sourceType": "competition"
    },
    {
     "datasetId": 7206260,
     "sourceId": 11495557,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7347136,
     "sourceId": 11719741,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 103.285054,
   "end_time": "2025-05-07T16:17:34.323547",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-07T16:15:51.038493",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
