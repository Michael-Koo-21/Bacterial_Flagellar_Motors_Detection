{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flagellar Motor Detection in Bacterial Tomograms\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook implements a solution for the BYU Locating Bacterial Flagellar Motors 2025 Kaggle competition. We'll develop an algorithm to automatically identify the presence and 3D coordinates of flagellar motors in cryogenic electron tomography (cryo-ET) data of bacteria.\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "Flagellar motors are molecular machines that enable bacterial movement. While cryo-ET imaging allows visualization in near-native conditions, identifying these structures in tomograms is challenging due to:\n",
    "\n",
    "- Poor signal-to-noise ratio (negative SNR values)\n",
    "- Variable tomogram sizes (especially z-axis)\n",
    "- Motors appearing as darker regions than surroundings\n",
    "- Variable motor orientations\n",
    "- Proximity to cell boundaries\n",
    "\n",
    "### Our Approach\n",
    "\n",
    "We'll implement a Ensemble Approach consiting of a 2D YOLOv8-based solution with 3D post-processing to find potential candidates and a 3D CNN to validate candidates, consisting of:\n",
    "1. Robust preprocessing with adaptive normalization\n",
    "2. YOLOv8 training with hyperparameter optimization\n",
    "3. Efficient slice processing during inference\n",
    "4. Advanced 3D clustering for final motor localization\n",
    "5. Two-stage detection pipeline:\n",
    "    - YOLO efficiently processes all 2D slices to find potential candidates\n",
    "    - 3D CNN validates candidates by analyzing the full 3D context around each potential motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T04:46:48.602643Z",
     "iopub.status.busy": "2025-05-07T04:46:48.602313Z",
     "iopub.status.idle": "2025-05-07T04:46:51.123878Z",
     "shell.execute_reply": "2025-05-07T04:46:51.122826Z",
     "shell.execute_reply.started": "2025-05-07T04:46:48.602612Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/yolo-pkg/yolo/ultralytics-8.3.112-py3-none-any.whl\n",
      "Installing collected packages: ultralytics\n",
      "Successfully installed ultralytics-8.3.112\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "import kagglehub\n",
    "kagglehub.dataset_download('rachiteagles/yolo-pkg')\n",
    "kagglehub.dataset_download('rachiteagles/yolo-model')\n",
    "\n",
    "# Install the YOLO package from the downloaded wheel file\n",
    "!pip install --no-index --no-deps /kaggle/input/yolo-pkg/yolo/ultralytics-8.3.112-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T04:47:11.249956Z",
     "iopub.status.busy": "2025-05-07T04:47:11.249662Z",
     "iopub.status.idle": "2025-05-07T04:47:16.798182Z",
     "shell.execute_reply": "2025-05-07T04:47:16.797260Z",
     "shell.execute_reply.started": "2025-05-07T04:47:11.249931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import torch\n",
    "import yaml\n",
    "import random\n",
    "import time\n",
    "import threading\n",
    "from tqdm.notebook import tqdm\n",
    "from contextlib import nullcontext\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from ultralytics import YOLO\n",
    "import shutil\n",
    "import optuna\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "# Define paths for Kaggle environment\n",
    "DATA_DIR = '/kaggle/input/byu-locating-bacterial-flagellar-motors-2025'\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, 'train_labels.csv')\n",
    "WORKING_DIR = '/kaggle/working'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration and Analysis\n",
    "\n",
    "Exploring the dataset to understand its characteristics before building our detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T04:48:28.105720Z",
     "iopub.status.busy": "2025-05-07T04:48:28.104909Z",
     "iopub.status.idle": "2025-05-07T04:48:28.187706Z",
     "shell.execute_reply": "2025-05-07T04:48:28.186944Z",
     "shell.execute_reply.started": "2025-05-07T04:48:28.105676Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def explore_dataset():\n",
    "    \"\"\"\n",
    "    Explore and analyze the dataset, returning key statistics and insights.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing dataset statistics\n",
    "    \"\"\"\n",
    "    # Load the training labels\n",
    "    train_labels = pd.read_csv(TRAIN_CSV)\n",
    "    \n",
    "    # Display the first few rows\n",
    "    display(train_labels.head())\n",
    "    \n",
    "    # Calculate basic statistics\n",
    "    total_records = len(train_labels)\n",
    "    unique_tomos = train_labels['tomo_id'].nunique()\n",
    "    tomos_with_motors = train_labels[train_labels['Number of motors'] > 0]['tomo_id'].nunique()\n",
    "    tomos_without_motors = unique_tomos - tomos_with_motors\n",
    "    percent_with_motors = (tomos_with_motors / unique_tomos) * 100\n",
    "    \n",
    "    # Calculate distribution of motors per tomogram\n",
    "    motors_per_tomo = train_labels.groupby('tomo_id')['Number of motors'].first()\n",
    "    motor_distribution = motors_per_tomo.value_counts().sort_index()\n",
    "    \n",
    "    # Tomogram shape statistics\n",
    "    axis_stats = {}\n",
    "    for axis in [0, 1, 2]:\n",
    "        axis_sizes = train_labels[f'Array shape (axis {axis})'].unique()\n",
    "        axis_stats[axis] = {\n",
    "            'sizes': sorted(axis_sizes),\n",
    "            'min': min(axis_sizes),\n",
    "            'max': max(axis_sizes),\n",
    "            'mean': np.mean(axis_sizes)\n",
    "        }\n",
    "    \n",
    "    # Voxel spacing statistics\n",
    "    voxel_spacing = train_labels['Voxel spacing'].unique()\n",
    "    voxel_stats = {\n",
    "        'values': sorted(voxel_spacing),\n",
    "        'min': min(voxel_spacing),\n",
    "        'max': max(voxel_spacing),\n",
    "        'mean': np.mean(voxel_spacing)\n",
    "    }\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"Total number of records: {total_records}\")\n",
    "    print(f\"Number of unique tomograms: {unique_tomos}\")\n",
    "    print(f\"Number of tomograms with motors: {tomos_with_motors}\")\n",
    "    print(f\"Number of tomograms without motors: {tomos_without_motors}\")\n",
    "    print(f\"Percentage of tomograms with motors: {percent_with_motors:.2f}%\")\n",
    "    \n",
    "    print(\"\\nDistribution of motors per tomogram:\")\n",
    "    display(motor_distribution)\n",
    "    \n",
    "    print(\"\\nTomogram size statistics:\")\n",
    "    for axis, stats in axis_stats.items():\n",
    "        print(f\"Axis {axis} sizes: {stats['sizes']}\")\n",
    "        print(f\"Min: {stats['min']}, Max: {stats['max']}, Mean: {stats['mean']:.2f}\")\n",
    "    \n",
    "    print(\"\\nVoxel spacing values (in angstroms per voxel):\")\n",
    "    print(voxel_stats['values'])\n",
    "    print(f\"Min: {voxel_stats['min']}, Max: {voxel_stats['max']}, Mean: {voxel_stats['mean']:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'train_labels': train_labels,\n",
    "        'total_records': total_records,\n",
    "        'unique_tomos': unique_tomos,\n",
    "        'tomos_with_motors': tomos_with_motors,\n",
    "        'tomos_without_motors': tomos_without_motors,\n",
    "        'percent_with_motors': percent_with_motors,\n",
    "        'motor_distribution': motor_distribution,\n",
    "        'axis_stats': axis_stats,\n",
    "        'voxel_stats': voxel_stats\n",
    "    }\n",
    "\n",
    "# Run data exploration\n",
    "dataset_stats = explore_dataset()\n",
    "train_labels = dataset_stats['train_labels']  # Store for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "\n",
    "Visualize sample tomogram slices with motors to better understand what we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T04:49:48.511775Z",
     "iopub.status.busy": "2025-05-07T04:49:48.511461Z",
     "iopub.status.idle": "2025-05-07T04:49:52.349419Z",
     "shell.execute_reply": "2025-05-07T04:49:52.348527Z",
     "shell.execute_reply.started": "2025-05-07T04:49:48.511753Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    \"\"\"\n",
    "    Class for processing and normalizing tomogram slices.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def normalize_slice(img_array, method='adaptive'):\n",
    "        \"\"\"\n",
    "        Normalize slice using different normalization methods\n",
    "        \n",
    "        Args:\n",
    "            img_array (np.ndarray): Input image array\n",
    "            method (str): Normalization method ('percentile', 'histogram', 'adaptive')\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Normalized image\n",
    "        \"\"\"\n",
    "        if method == 'percentile':\n",
    "            # Percentile-based normalization (2nd to 98th percentile)\n",
    "            p2 = np.percentile(img_array, 2)\n",
    "            p98 = np.percentile(img_array, 98)\n",
    "            normalized = np.clip(img_array, p2, p98)\n",
    "            normalized = 255 * (normalized - p2) / (p98 - p2)\n",
    "            return np.uint8(normalized)\n",
    "        \n",
    "        elif method == 'histogram':\n",
    "            # Histogram equalization\n",
    "            return cv2.equalizeHist(img_array)\n",
    "        \n",
    "        elif method == 'adaptive':\n",
    "            # Combination of methods\n",
    "            # First apply percentile normalization\n",
    "            p2 = np.percentile(img_array, 2)\n",
    "            p98 = np.percentile(img_array, 98)\n",
    "            normalized = np.clip(img_array, p2, p98)\n",
    "            normalized = 255 * (normalized - p2) / (p98 - p2)\n",
    "            normalized = np.uint8(normalized)\n",
    "            \n",
    "            # Then apply adaptive histogram equalization\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            return clahe.apply(normalized)\n",
    "        \n",
    "        else:\n",
    "            return img_array\n",
    "\n",
    "def visualize_motor_slices(train_labels, n_samples=3, context_slices=2):\n",
    "    \"\"\"\n",
    "    Visualize motor slices with context slices above and below\n",
    "    \n",
    "    Args:\n",
    "        train_labels (pd.DataFrame): DataFrame with motor annotations\n",
    "        n_samples (int): Number of random motors to visualize\n",
    "        context_slices (int): Number of slices to show above and below motor\n",
    "    \"\"\"\n",
    "    # Get tomograms with motors\n",
    "    motors_df = train_labels[(~pd.isna(train_labels['Motor axis 0'])) & \n",
    "                            (train_labels['Motor axis 0'] > 0)]\n",
    "    \n",
    "    if len(motors_df) == 0:\n",
    "        print(\"No valid motors found in the dataset!\")\n",
    "        return\n",
    "    \n",
    "    # Sample random motors\n",
    "    sample_motors = motors_df.sample(min(n_samples, len(motors_df)))\n",
    "    \n",
    "    # Create figure\n",
    "    fig_height = 4 * n_samples\n",
    "    fig_width = 4 * (2*context_slices + 1)\n",
    "    fig, axes = plt.subplots(n_samples, 2*context_slices + 1, figsize=(fig_width, fig_height))\n",
    "    \n",
    "    # Handle the case of a single sample\n",
    "    if n_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    # Process each sample\n",
    "    for i, (_, motor) in enumerate(sample_motors.iterrows()):\n",
    "        tomo_id = motor['tomo_id']\n",
    "        z_center = int(motor['Motor axis 0'])\n",
    "        y_center = int(motor['Motor axis 1'])\n",
    "        x_center = int(motor['Motor axis 2'])\n",
    "        \n",
    "        # Get slice range - ensure we have valid positive indices\n",
    "        z_min = max(1, z_center - context_slices)  # Start at 1 to avoid issues with 0\n",
    "        z_max = min(int(motor['Array shape (axis 0)']) - 1, z_center + context_slices)\n",
    "        \n",
    "        # Calculate actual number of slices to display\n",
    "        n_slices = z_max - z_min + 1\n",
    "        \n",
    "        # Load and display slices\n",
    "        for j, z in enumerate(range(z_min, z_max + 1)):\n",
    "            try:\n",
    "                # Create slice filename with proper formatting\n",
    "                slice_filename = f\"slice_{z:04d}.jpg\"\n",
    "                slice_path = os.path.join(TRAIN_DIR, tomo_id, slice_filename)\n",
    "                \n",
    "                if os.path.exists(slice_path):\n",
    "                    # Load and normalize slice\n",
    "                    img = np.array(Image.open(slice_path))\n",
    "                    normalized_img = ImageProcessor.normalize_slice(img, 'adaptive')\n",
    "                    \n",
    "                    # Display the image\n",
    "                    axes[i, j].imshow(normalized_img, cmap='gray')\n",
    "                    \n",
    "                    # Draw bounding box on the motor slice\n",
    "                    if z == z_center:\n",
    "                        box_size = 24  # Reasonable motor size\n",
    "                        rect = plt.Rectangle((x_center - box_size//2, y_center - box_size//2), \n",
    "                                            box_size, box_size, \n",
    "                                            linewidth=2, edgecolor='r', facecolor='none')\n",
    "                        axes[i, j].add_patch(rect)\n",
    "                        axes[i, j].set_title(f\"Motor Slice (z={z})\", color='red')\n",
    "                    else:\n",
    "                        axes[i, j].set_title(f\"Slice z={z}\")\n",
    "                    \n",
    "                    axes[i, j].axis('on')\n",
    "                    axes[i, j].set_xticks([])\n",
    "                    axes[i, j].set_yticks([])\n",
    "                else:\n",
    "                    axes[i, j].text(0.5, 0.5, f\"Slice {z} not found\", \n",
    "                                  horizontalalignment='center', verticalalignment='center')\n",
    "                    axes[i, j].axis('off')\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing slice z={z} for tomogram {tomo_id}: {e}\")\n",
    "                axes[i, j].text(0.5, 0.5, f\"Error with slice {z}\", \n",
    "                              horizontalalignment='center', verticalalignment='center')\n",
    "                axes[i, j].axis('off')\n",
    "        \n",
    "        # Clear any unused subplot axes\n",
    "        for j in range(n_slices, len(axes[i])):\n",
    "            axes[i, j].axis('off')\n",
    "        \n",
    "        # Add text with motor coordinates\n",
    "        plt.figtext(0.01, 0.95 - (i * 1/n_samples), \n",
    "                   f\"Tomogram: {tomo_id}\\nMotor at: z={z_center}, y={y_center}, x={x_center}\", \n",
    "                   fontsize=9, bbox=dict(facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compare_normalization_methods(train_labels):\n",
    "    \"\"\"\n",
    "    Compare different normalization methods on the same slice\n",
    "    \n",
    "    Args:\n",
    "        train_labels (pd.DataFrame): DataFrame with motor annotations\n",
    "    \"\"\"\n",
    "    # Get a tomogram with a motor\n",
    "    valid_motors = train_labels[(~pd.isna(train_labels['Motor axis 0'])) & \n",
    "                             (train_labels['Motor axis 0'] > 0)]\n",
    "    \n",
    "    if len(valid_motors) == 0:\n",
    "        print(\"No valid motors found in the dataset!\")\n",
    "        return\n",
    "        \n",
    "    sample_motor = valid_motors.iloc[0]\n",
    "    tomo_id = sample_motor['tomo_id']\n",
    "    z_center = int(sample_motor['Motor axis 0'])\n",
    "    y_center = int(sample_motor['Motor axis 1'])\n",
    "    x_center = int(sample_motor['Motor axis 2'])\n",
    "    \n",
    "    # Load the slice\n",
    "    slice_filename = f\"slice_{z_center:04d}.jpg\"\n",
    "    slice_path = os.path.join(TRAIN_DIR, tomo_id, slice_filename)\n",
    "    \n",
    "    if not os.path.exists(slice_path):\n",
    "        print(f\"Slice {slice_path} not found!\")\n",
    "        return\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "    # Original image\n",
    "    original_img = np.array(Image.open(slice_path))\n",
    "    axes[0].imshow(original_img, cmap='gray')\n",
    "    axes[0].set_title(\"Original\")\n",
    "    \n",
    "    # Percentile normalization\n",
    "    percentile_img = ImageProcessor.normalize_slice(original_img, 'percentile')\n",
    "    axes[1].imshow(percentile_img, cmap='gray')\n",
    "    axes[1].set_title(\"Percentile (2-98)\")\n",
    "    \n",
    "    # Histogram equalization\n",
    "    hist_img = ImageProcessor.normalize_slice(original_img, 'histogram')\n",
    "    axes[2].imshow(hist_img, cmap='gray')\n",
    "    axes[2].set_title(\"Histogram Equalization\")\n",
    "    \n",
    "    # Adaptive normalization\n",
    "    adaptive_img = ImageProcessor.normalize_slice(original_img, 'adaptive')\n",
    "    axes[3].imshow(adaptive_img, cmap='gray')\n",
    "    axes[3].set_title(\"Adaptive (Combined)\")\n",
    "    \n",
    "    # Draw bounding box on all images\n",
    "    box_size = 24\n",
    "    for ax in axes:\n",
    "        rect = plt.Rectangle((x_center - box_size//2, y_center - box_size//2), \n",
    "                            box_size, box_size, \n",
    "                            linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.axis('on')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.suptitle(f\"Normalization methods comparison for {tomo_id}, Motor at z={z_center}, y={y_center}, x={x_center}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize sample motors\n",
    "visualize_motor_slices(train_labels, 3, 2)\n",
    "\n",
    "# Compare normalization methods\n",
    "compare_normalization_methods(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing Pipeline\n",
    "\n",
    "Preprocessing pipeline that prepares our data for the YOLO model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T04:51:06.914588Z",
     "iopub.status.busy": "2025-05-07T04:51:06.914179Z",
     "iopub.status.idle": "2025-05-07T04:54:51.903112Z",
     "shell.execute_reply": "2025-05-07T04:54:51.902432Z",
     "shell.execute_reply.started": "2025-05-07T04:51:06.914562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TomogramProcessor:\n",
    "    \"\"\"\n",
    "    Comprehensive tomogram processing class for extracting, normalizing, \n",
    "    and preparing slices for YOLO training.\n",
    "    \"\"\"\n",
    "    def __init__(self, train_dir, labels_df, working_dir, \n",
    "                 context_range=5, box_size=24, test_split=0.2, \n",
    "                 norm_method='adaptive'):\n",
    "        \"\"\"\n",
    "        Initialize the processor\n",
    "        \n",
    "        Args:\n",
    "            train_dir (str): Path to directory containing training tomograms\n",
    "            labels_df (pd.DataFrame): DataFrame with motor annotations\n",
    "            working_dir (str): Path to working directory for processed data\n",
    "            context_range (int): Number of slices to include above and below motors\n",
    "            box_size (int): Size of bounding box for motor annotations\n",
    "            test_split (float): Fraction of tomograms to use for validation\n",
    "            norm_method (str): Normalization method to use\n",
    "        \"\"\"\n",
    "        self.train_dir = train_dir\n",
    "        self.labels_df = labels_df\n",
    "        self.working_dir = working_dir\n",
    "        self.context_range = context_range\n",
    "        self.box_size = box_size\n",
    "        self.test_split = test_split\n",
    "        self.norm_method = norm_method\n",
    "        \n",
    "        # Define YOLO dataset structure\n",
    "        self.yolo_dataset_dir = os.path.join(working_dir, \"yolo_dataset\")\n",
    "        self.yolo_images_train = os.path.join(self.yolo_dataset_dir, \"images\", \"train\")\n",
    "        self.yolo_images_val = os.path.join(self.yolo_dataset_dir, \"images\", \"val\")\n",
    "        self.yolo_labels_train = os.path.join(self.yolo_dataset_dir, \"labels\", \"train\")\n",
    "        self.yolo_labels_val = os.path.join(self.yolo_dataset_dir, \"labels\", \"val\")\n",
    "        \n",
    "        # Create directories\n",
    "        for dir_path in [self.yolo_images_train, self.yolo_images_val, \n",
    "                         self.yolo_labels_train, self.yolo_labels_val]:\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    def normalize_slice(self, img_array):\n",
    "        \"\"\"\n",
    "        Normalize slice using the specified method\n",
    "        \n",
    "        Args:\n",
    "            img_array (np.ndarray): Input image array\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Normalized image\n",
    "        \"\"\"\n",
    "        return ImageProcessor.normalize_slice(img_array, self.norm_method)\n",
    "    \n",
    "    def prepare_dataset(self):\n",
    "        \"\"\"\n",
    "        Prepare the YOLO dataset by extracting slices and creating annotations\n",
    "        \n",
    "        Returns:\n",
    "            dict: Summary information about the prepared dataset\n",
    "        \"\"\"\n",
    "        # Filter to get only tomograms with motors\n",
    "        tomo_df = self.labels_df[self.labels_df['Number of motors'] > 0].copy()\n",
    "        unique_tomos = tomo_df['tomo_id'].unique()\n",
    "        \n",
    "        print(f\"Found {len(unique_tomos)} unique tomograms with motors\")\n",
    "        \n",
    "        # Perform a train-val split at the tomogram level\n",
    "        np.random.shuffle(unique_tomos)\n",
    "        split_idx = int(len(unique_tomos) * (1 - self.test_split))\n",
    "        train_tomos = unique_tomos[:split_idx]\n",
    "        val_tomos = unique_tomos[split_idx:]\n",
    "        \n",
    "        print(f\"Split: {len(train_tomos)} tomograms for training, {len(val_tomos)} tomograms for validation\")\n",
    "        \n",
    "        # Process training tomograms\n",
    "        train_slices, train_motors = self._process_tomogram_set(\n",
    "            train_tomos, self.yolo_images_train, self.yolo_labels_train, \"training\")\n",
    "        \n",
    "        # Process validation tomograms\n",
    "        val_slices, val_motors = self._process_tomogram_set(\n",
    "            val_tomos, self.yolo_images_val, self.yolo_labels_val, \"validation\")\n",
    "        \n",
    "        # Create YAML configuration file for YOLO\n",
    "        yaml_content = {\n",
    "            'path': self.yolo_dataset_dir,\n",
    "            'train': 'images/train',\n",
    "            'val': 'images/val',\n",
    "            'names': {0: 'motor'}\n",
    "        }\n",
    "        \n",
    "        yaml_path = os.path.join(self.yolo_dataset_dir, 'dataset.yaml')\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "        \n",
    "        print(f\"\\nProcessing Summary:\")\n",
    "        print(f\"- Train set: {len(train_tomos)} tomograms, {train_motors} motors, {train_slices} slices\")\n",
    "        print(f\"- Validation set: {len(val_tomos)} tomograms, {val_motors} motors, {val_slices} slices\")\n",
    "        print(f\"- Total: {len(train_tomos) + len(val_tomos)} tomograms, {train_motors + val_motors} motors, {train_slices + val_slices} slices\")\n",
    "        \n",
    "        # Return summary info\n",
    "        return {\n",
    "            \"dataset_dir\": self.yolo_dataset_dir,\n",
    "            \"yaml_path\": yaml_path,\n",
    "            \"train_tomograms\": len(train_tomos),\n",
    "            \"val_tomograms\": len(val_tomos),\n",
    "            \"train_motors\": train_motors,\n",
    "            \"val_motors\": val_motors,\n",
    "            \"train_slices\": train_slices,\n",
    "            \"val_slices\": val_slices\n",
    "        }\n",
    "    \n",
    "    def _process_tomogram_set(self, tomogram_ids, images_dir, labels_dir, set_name):\n",
    "        \"\"\"\n",
    "        Process a set of tomograms to extract slices and create annotations\n",
    "        \n",
    "        Args:\n",
    "            tomogram_ids (list): List of tomogram IDs to process\n",
    "            images_dir (str): Directory to save extracted images\n",
    "            labels_dir (str): Directory to save labels\n",
    "            set_name (str): Name of the dataset (for logging)\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (Number of processed slices, Number of motors)\n",
    "        \"\"\"\n",
    "        motor_counts = []\n",
    "        for tomo_id in tomogram_ids:\n",
    "            # Get all motors for this tomogram\n",
    "            tomo_motors = self.labels_df[self.labels_df['tomo_id'] == tomo_id]\n",
    "            for _, motor in tomo_motors.iterrows():\n",
    "                if pd.isna(motor['Motor axis 0']):\n",
    "                    continue\n",
    "                motor_counts.append(\n",
    "                    (tomo_id, \n",
    "                     int(motor['Motor axis 0']), \n",
    "                     int(motor['Motor axis 1']), \n",
    "                     int(motor['Motor axis 2']),\n",
    "                     int(motor['Array shape (axis 0)']))\n",
    "                )\n",
    "        \n",
    "        print(f\"Will process approximately {len(motor_counts) * (2 * self.context_range + 1)} slices for {set_name}\")\n",
    "        \n",
    "        # Process each motor\n",
    "        processed_slices = 0\n",
    "        \n",
    "        for tomo_id, z_center, y_center, x_center, z_max in tqdm(motor_counts, desc=f\"Processing {set_name} motors\"):\n",
    "            # Calculate range of slices to include\n",
    "            z_min = max(0, z_center - self.context_range)\n",
    "            z_max = min(z_max - 1, z_center + self.context_range)\n",
    "            \n",
    "            # Process each slice in the range\n",
    "            for z in range(z_min, z_max + 1):\n",
    "                # Create slice filename\n",
    "                slice_filename = f\"slice_{z:04d}.jpg\"\n",
    "                \n",
    "                # Source path for the slice\n",
    "                src_path = os.path.join(self.train_dir, tomo_id, slice_filename)\n",
    "                \n",
    "                if not os.path.exists(src_path):\n",
    "                    print(f\"Warning: {src_path} does not exist, skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Load and normalize the slice\n",
    "                img = Image.open(src_path)\n",
    "                img_array = np.array(img)\n",
    "                \n",
    "                # Normalize the image\n",
    "                normalized_img = self.normalize_slice(img_array)\n",
    "                \n",
    "                # Create destination filename (with unique identifier)\n",
    "                dest_filename = f\"{tomo_id}_z{z:04d}_y{y_center:04d}_x{x_center:04d}.jpg\"\n",
    "                dest_path = os.path.join(images_dir, dest_filename)\n",
    "                \n",
    "                # Save the normalized image\n",
    "                Image.fromarray(normalized_img).save(dest_path)\n",
    "                \n",
    "                # Get image dimensions\n",
    "                img_width, img_height = img.size\n",
    "                \n",
    "                # Create YOLO format label\n",
    "                # YOLO format: <class> <x_center> <y_center> <width> <height>\n",
    "                # Values are normalized to [0, 1]\n",
    "                x_center_norm = x_center / img_width\n",
    "                y_center_norm = y_center / img_height\n",
    "                box_width_norm = self.box_size / img_width\n",
    "                box_height_norm = self.box_size / img_height\n",
    "                \n",
    "                # Write label file\n",
    "                label_path = os.path.join(labels_dir, dest_filename.replace('.jpg', '.txt'))\n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.write(f\"0 {x_center_norm} {y_center_norm} {box_width_norm} {box_height_norm}\\n\")\n",
    "                \n",
    "                processed_slices += 1\n",
    "        \n",
    "        return processed_slices, len(motor_counts)\n",
    "\n",
    "# Create and run the tomogram processor\n",
    "processor = TomogramProcessor(\n",
    "    train_dir=TRAIN_DIR,\n",
    "    labels_df=train_labels,\n",
    "    working_dir=WORKING_DIR,\n",
    "    context_range=5,  # Include 5 slices above and below each motor\n",
    "    box_size=24,      # 24x24 bounding box for motors\n",
    "    test_split=0.2,   # 20% of tomograms for validation\n",
    "    norm_method='adaptive'  # Use adaptive normalization\n",
    ")\n",
    "\n",
    "# Prepare the dataset\n",
    "dataset_summary = processor.prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training with Hyperparameter Optimization\n",
    "\n",
    "Implement a training pipeline with hyperparameter optimization for our YOLOv8 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T04:55:06.166379Z",
     "iopub.status.busy": "2025-05-07T04:55:06.166022Z",
     "iopub.status.idle": "2025-05-07T07:35:01.120024Z",
     "shell.execute_reply": "2025-05-07T07:35:01.118715Z",
     "shell.execute_reply.started": "2025-05-07T04:55:06.166347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class YOLOTrainer:\n",
    "    \"\"\"\n",
    "    YOLOv8 training class with hyperparameter optimization\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_yaml, working_dir):\n",
    "        \"\"\"\n",
    "        Initialize the trainer\n",
    "        \n",
    "        Args:\n",
    "            dataset_yaml (str): Path to YOLO dataset YAML file\n",
    "            working_dir (str): Working directory for outputs\n",
    "        \"\"\"\n",
    "        self.dataset_yaml = dataset_yaml\n",
    "        self.working_dir = working_dir\n",
    "        self.weights_dir = os.path.join(working_dir, \"yolo_weights\")\n",
    "        self.model_name = \"motor_detector\"\n",
    "        \n",
    "        # Create weights directory\n",
    "        os.makedirs(self.weights_dir, exist_ok=True)\n",
    "    \n",
    "    def train_model(self, pretrained_weights, epochs=30, batch_size=16, img_size=640,\n",
    "                   optimizer='AdamW', lr=1e-4, dropout=0.1, patience=5, box=7.5, cls=0.5, dfl=1.5):\n",
    "        \"\"\"\n",
    "        Train the YOLO model with specified hyperparameters\n",
    "        \n",
    "        Args:\n",
    "            pretrained_weights (str): Path to pretrained weights file\n",
    "            epochs (int): Number of training epochs\n",
    "            batch_size (int): Batch size for training\n",
    "            img_size (int): Input image size\n",
    "            optimizer (str): Optimizer to use\n",
    "            lr (float): Learning rate\n",
    "            dropout (float): Dropout rate\n",
    "            patience (int): Early stopping patience\n",
    "            box (float): Box loss gain\n",
    "            cls (float): Class loss gain\n",
    "            dfl (float): DFL loss gain\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (Trained model, Training results)\n",
    "        \"\"\"\n",
    "        print(f\"Training YOLO model with:\")\n",
    "        print(f\"- Pretrained weights: {pretrained_weights}\")\n",
    "        print(f\"- Epochs: {epochs}\")\n",
    "        print(f\"- Batch size: {batch_size}\")\n",
    "        print(f\"- Image size: {img_size}\")\n",
    "        print(f\"- Optimizer: {optimizer}, LR: {lr}\")\n",
    "        print(f\"- Loss gains: box={box}, cls={cls}, dfl={dfl}\")\n",
    "        \n",
    "        # Load a model\n",
    "        model = YOLO(pretrained_weights)\n",
    "        \n",
    "        # Train the model with specified hyperparameters\n",
    "        results = model.train(\n",
    "            data=self.dataset_yaml,\n",
    "            epochs=epochs,\n",
    "            batch=batch_size,\n",
    "            imgsz=img_size,\n",
    "            optimizer=optimizer,\n",
    "            lr0=lr,\n",
    "            lrf=0.01,\n",
    "            momentum=0.937,\n",
    "            weight_decay=0.0005,\n",
    "            warmup_epochs=3.0,\n",
    "            warmup_momentum=0.8,\n",
    "            warmup_bias_lr=0.1,\n",
    "            box=box,\n",
    "            cls=cls,\n",
    "            dfl=dfl,\n",
    "            hsv_h=0.015,\n",
    "            hsv_s=0.7,\n",
    "            hsv_v=0.4,\n",
    "            degrees=45.0,\n",
    "            translate=0.1,\n",
    "            scale=0.5,\n",
    "            fliplr=0.5,\n",
    "            mosaic=1.0,\n",
    "            mixup=0.1,\n",
    "            dropout=dropout,\n",
    "            project=self.weights_dir,\n",
    "            name=self.model_name,\n",
    "            exist_ok=True,\n",
    "            patience=patience,\n",
    "            save_period=5,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Get run directory\n",
    "        run_dir = os.path.join(self.weights_dir, self.model_name)\n",
    "        \n",
    "        # Plot DFL loss curve\n",
    "        self.plot_dfl_loss_curve(run_dir)\n",
    "        \n",
    "        return model, results\n",
    "    \n",
    "    def plot_dfl_loss_curve(self, run_dir):\n",
    "        \"\"\"\n",
    "        Plot the DFL loss curves for train and validation\n",
    "        \n",
    "        Args:\n",
    "            run_dir (str): Directory where the training results are stored\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (Best epoch, Best validation loss)\n",
    "        \"\"\"\n",
    "        # Path to the results CSV file\n",
    "        results_csv = os.path.join(run_dir, 'results.csv')\n",
    "        \n",
    "        if not os.path.exists(results_csv):\n",
    "            print(f\"Results file not found at {results_csv}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Read results CSV\n",
    "        results_df = pd.read_csv(results_csv)\n",
    "        \n",
    "        # Check if DFL loss columns exist\n",
    "        train_dfl_col = [col for col in results_df.columns if 'train/dfl_loss' in col]\n",
    "        val_dfl_col = [col for col in results_df.columns if 'val/dfl_loss' in col]\n",
    "        \n",
    "        if not train_dfl_col or not val_dfl_col:\n",
    "            print(\"DFL loss columns not found in results CSV\")\n",
    "            print(f\"Available columns: {results_df.columns.tolist()}\")\n",
    "            return None, None\n",
    "        \n",
    "        train_dfl_col = train_dfl_col[0]\n",
    "        val_dfl_col = val_dfl_col[0]\n",
    "        \n",
    "        # Find the epoch with the best validation loss\n",
    "        best_epoch = results_df[val_dfl_col].idxmin()\n",
    "        best_val_loss = results_df.loc[best_epoch, val_dfl_col]\n",
    "        \n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Plot training and validation losses\n",
    "        plt.plot(results_df['epoch'], results_df[train_dfl_col], label='Train DFL Loss')\n",
    "        plt.plot(results_df['epoch'], results_df[val_dfl_col], label='Validation DFL Loss')\n",
    "        \n",
    "        # Mark the best model with a vertical line\n",
    "        plt.axvline(x=results_df.loc[best_epoch, 'epoch'], color='r', linestyle='--', \n",
    "                    label=f'Best Model (Epoch {int(results_df.loc[best_epoch, \"epoch\"])}, Val Loss: {best_val_loss:.4f})')\n",
    "        \n",
    "        # Add labels and legend\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('DFL Loss')\n",
    "        plt.title('Training and Validation DFL Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Save the plot\n",
    "        plot_path = os.path.join(run_dir, 'dfl_loss_curve.png')\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Loss curve saved to {plot_path}\")\n",
    "        \n",
    "        return best_epoch, best_val_loss\n",
    "    \n",
    "    def optimize_hyperparameters(self, n_trials=10, max_epochs=15):\n",
    "        \"\"\"\n",
    "        Perform hyperparameter optimization using Optuna\n",
    "        \n",
    "        Args:\n",
    "            n_trials (int): Number of optimization trials\n",
    "            max_epochs (int): Maximum epochs per trial\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (Best hyperparameters, Final model)\n",
    "        \"\"\"\n",
    "        print(f\"Starting hyperparameter optimization with {n_trials} trials\")\n",
    "        \n",
    "        def objective(trial):\n",
    "            # Define hyperparameters to optimize\n",
    "            pretrained_model = trial.suggest_categorical(\"pretrained_model\", \n",
    "                                                        [\"yolov8n.pt\", \"yolov8s.pt\", \"yolov8m.pt\"])\n",
    "            batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "            img_size = trial.suggest_categorical(\"img_size\", [640, 800, 960])\n",
    "            optimizer = trial.suggest_categorical(\"optimizer\", [\"AdamW\", \"SGD\"])\n",
    "            lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "            dropout = trial.suggest_float(\"dropout\", 0.0, 0.3)\n",
    "            box_gain = trial.suggest_float(\"box_gain\", 5.0, 10.0)\n",
    "            cls_gain = trial.suggest_float(\"cls_gain\", 0.3, 1.0)\n",
    "            dfl_gain = trial.suggest_float(\"dfl_gain\", 1.0, 2.0)\n",
    "            \n",
    "            # Create a unique name for this trial\n",
    "            trial_name = f\"{self.model_name}_trial_{trial.number}\"\n",
    "            \n",
    "            # Train with these hyperparameters\n",
    "            try:\n",
    "                model = YOLO(pretrained_model)\n",
    "                \n",
    "                # Use fewer epochs for optimization trials\n",
    "                results = model.train(\n",
    "                    data=self.dataset_yaml,\n",
    "                    epochs=max_epochs,\n",
    "                    batch=batch_size,\n",
    "                    imgsz=img_size,\n",
    "                    optimizer=optimizer,\n",
    "                    lr0=lr,\n",
    "                    lrf=0.01,\n",
    "                    box=box_gain,\n",
    "                    cls=cls_gain,\n",
    "                    dfl=dfl_gain,\n",
    "                    dropout=dropout,\n",
    "                    project=self.weights_dir,\n",
    "                    name=trial_name,\n",
    "                    exist_ok=True,\n",
    "                    patience=3,  # Early stopping for trials\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                # Get results path\n",
    "                results_csv = os.path.join(self.weights_dir, trial_name, 'results.csv')\n",
    "                \n",
    "                if os.path.exists(results_csv):\n",
    "                    # Read results CSV to get validation loss\n",
    "                    results_df = pd.read_csv(results_csv)\n",
    "                    val_dfl_cols = [col for col in results_df.columns if 'val/dfl_loss' in col]\n",
    "                    \n",
    "                    if val_dfl_cols:\n",
    "                        # Get the best validation loss\n",
    "                        val_dfl_col = val_dfl_cols[0]\n",
    "                        best_val_loss = results_df[val_dfl_col].min()\n",
    "                        \n",
    "                        # Return the loss (to be minimized)\n",
    "                        return best_val_loss\n",
    "                \n",
    "                # If something went wrong, return a high loss\n",
    "                return float('inf')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in trial {trial.number}: {e}\")\n",
    "                return float('inf')\n",
    "        \n",
    "        # Create study and optimize\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        study.optimize(objective, n_trials=n_trials)\n",
    "        \n",
    "        # Get best parameters\n",
    "        best_params = study.best_params\n",
    "        print(\"Best hyperparameters found:\")\n",
    "        for param, value in best_params.items():\n",
    "            print(f\"- {param}: {value}\")\n",
    "        \n",
    "        # Train final model with best parameters\n",
    "        print(\"\\nTraining final model with best hyperparameters...\")\n",
    "        final_model, _ = self.train_model(\n",
    "            pretrained_weights=best_params[\"pretrained_model\"],\n",
    "            batch_size=best_params[\"batch_size\"],\n",
    "            img_size=best_params[\"img_size\"],\n",
    "            optimizer=best_params[\"optimizer\"],\n",
    "            lr=best_params[\"lr\"],\n",
    "            dropout=best_params[\"dropout\"],\n",
    "            box=best_params[\"box_gain\"],\n",
    "            cls=best_params[\"cls_gain\"],\n",
    "            dfl=best_params[\"dfl_gain\"],\n",
    "            epochs=30,  # Use more epochs for final model\n",
    "            patience=5\n",
    "        )\n",
    "        \n",
    "        return best_params, final_model\n",
    "    \n",
    "    def predict_on_samples(self, model, num_samples=4):\n",
    "        \"\"\"\n",
    "        Run predictions on random validation samples and display results\n",
    "        \n",
    "        Args:\n",
    "            model: Trained YOLO model\n",
    "            num_samples (int): Number of random samples to display\n",
    "        \"\"\"\n",
    "        # Get validation images directory\n",
    "        val_dir = os.path.join(os.path.dirname(self.dataset_yaml), 'images', 'val')\n",
    "        \n",
    "        if not os.path.exists(val_dir):\n",
    "            print(f\"Validation directory not found at {val_dir}\")\n",
    "            return\n",
    "        \n",
    "        # Get all validation images\n",
    "        val_images = [f for f in os.listdir(val_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        \n",
    "        if not val_images:\n",
    "            print(\"No validation images found.\")\n",
    "            return\n",
    "        \n",
    "        # Select random samples\n",
    "        samples = random.sample(val_images, min(num_samples, len(val_images)))\n",
    "        \n",
    "        # Create figure\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, img_file in enumerate(samples):\n",
    "            if i >= len(axes):\n",
    "                break\n",
    "            \n",
    "            # Full image path\n",
    "            img_path = os.path.join(val_dir, img_file)\n",
    "            \n",
    "            # Run prediction\n",
    "            results = model.predict(img_path, conf=0.25)[0]\n",
    "            \n",
    "            # Load the image\n",
    "            img = Image.open(img_path)\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Display image\n",
    "            axes[i].imshow(img_array, cmap='gray')\n",
    "            \n",
    "            # Parse ground truth from filename\n",
    "            # Format: tomo_id_zXXXX_yYYYY_xZZZZ.jpg\n",
    "            parts = img_file.split('_')\n",
    "            y_coord = None\n",
    "            x_coord = None\n",
    "            \n",
    "            for part in parts:\n",
    "                if part.startswith('y'):\n",
    "                    try:\n",
    "                        y_coord = int(part[1:])\n",
    "                    except:\n",
    "                        pass\n",
    "                elif part.startswith('x'):\n",
    "                    try:\n",
    "                        x_coord = int(part.split('.')[0][1:])\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            # Draw ground truth box if coordinates found\n",
    "            if y_coord is not None and x_coord is not None:\n",
    "                box_size = 24\n",
    "                rect_gt = plt.Rectangle((x_coord - box_size//2, y_coord - box_size//2), \n",
    "                                     box_size, box_size, \n",
    "                                     linewidth=1, edgecolor='g', facecolor='none')\n",
    "                axes[i].add_patch(rect_gt)\n",
    "                axes[i].text(x_coord - box_size//2, y_coord - box_size//2 - 5, \n",
    "                          \"Ground Truth\", color='green', fontsize=8)\n",
    "            \n",
    "            # Draw predictions\n",
    "            if len(results.boxes) > 0:\n",
    "                boxes = results.boxes.xyxy.cpu().numpy()\n",
    "                confs = results.boxes.conf.cpu().numpy()\n",
    "                \n",
    "                for box, conf in zip(boxes, confs):\n",
    "                    x1, y1, x2, y2 = box\n",
    "                    rect_pred = plt.Rectangle((x1, y1), x2-x1, y2-y1, \n",
    "                                          linewidth=1, edgecolor='r', facecolor='none')\n",
    "                    axes[i].add_patch(rect_pred)\n",
    "                    axes[i].text(x1, y1-5, f'Conf: {conf:.2f}', color='red', fontsize=8)\n",
    "            \n",
    "            axes[i].set_title(f\"Image: {img_file}\")\n",
    "            axes[i].axis('on')\n",
    "            axes[i].set_xticks([])\n",
    "            axes[i].set_yticks([])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.weights_dir, 'sample_predictions.png'))\n",
    "        plt.show()\n",
    "\n",
    "# Create the YOLOTrainer\n",
    "trainer = YOLOTrainer(\n",
    "    dataset_yaml=dataset_summary['yaml_path'],\n",
    "    working_dir=WORKING_DIR\n",
    ")\n",
    "\n",
    "# Run hyperparameter optimization and get the best model\n",
    "print(\"Starting YOLO model training with hyperparameter optimization...\")\n",
    "best_params, yolo_model = trainer.optimize_hyperparameters(n_trials=5, max_epochs=10)\n",
    "\n",
    "# Visualize predictions on validation samples\n",
    "trainer.predict_on_samples(yolo_model, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 3D CNN Implementation\n",
    "\n",
    "Implement a complementary 3D CNN approach that can better capture the volumetric nature of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T05:56:27.315828Z",
     "iopub.status.busy": "2025-05-06T05:56:27.315524Z",
     "iopub.status.idle": "2025-05-06T05:56:27.345571Z",
     "shell.execute_reply": "2025-05-06T05:56:27.344756Z",
     "shell.execute_reply.started": "2025-05-06T05:56:27.315807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AttentionBlock(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    3D attention block for focusing on motor-specific features\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels):\n",
    "        \"\"\"\n",
    "        Initialize the attention block\n",
    "        \n",
    "        Args:\n",
    "            in_channels (int): Number of input channels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.query = torch.nn.Conv3d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.key = torch.nn.Conv3d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.value = torch.nn.Conv3d(in_channels, in_channels, kernel_size=1)\n",
    "        self.gamma = torch.nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the attention block\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor with attention applied\n",
    "        \"\"\"\n",
    "        batch_size, channels, depth, height, width = x.size()\n",
    "        \n",
    "        # Reshape for attention calculation\n",
    "        query = self.query(x).view(batch_size, -1, depth * height * width).permute(0, 2, 1)\n",
    "        key = self.key(x).view(batch_size, -1, depth * height * width)\n",
    "        value = self.value(x).view(batch_size, -1, depth * height * width)\n",
    "        \n",
    "        # Calculate attention\n",
    "        attention = torch.bmm(query, key)\n",
    "        attention = self.softmax(attention)\n",
    "        \n",
    "        # Apply attention\n",
    "        out = torch.bmm(value, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch_size, channels, depth, height, width)\n",
    "        \n",
    "        # Residual connection\n",
    "        out = self.gamma * out + x\n",
    "        return out\n",
    "\n",
    "class Motor3DCNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    3D CNN for detecting flagellar motors in tomogram volumes\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels=1, dropout_rate=0.3):\n",
    "        \"\"\"\n",
    "        Initialize the 3D CNN model\n",
    "        \n",
    "        Args:\n",
    "            input_channels (int): Number of input channels\n",
    "            dropout_rate (float): Dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initial convolution layers\n",
    "        self.conv1 = torch.nn.Conv3d(input_channels, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm3d(16)\n",
    "        self.conv2 = torch.nn.Conv3d(16, 32, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn2 = torch.nn.BatchNorm3d(32)\n",
    "        self.conv3 = torch.nn.Conv3d(32, 64, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn3 = torch.nn.BatchNorm3d(64)\n",
    "        self.conv4 = torch.nn.Conv3d(64, 128, kernel_size=3, padding=1, stride=2)\n",
    "        self.bn4 = torch.nn.BatchNorm3d(128)\n",
    "        \n",
    "        # Attention block\n",
    "        self.attention = AttentionBlock(128)\n",
    "        \n",
    "        # Global average pooling\n",
    "        self.global_avg_pool = torch.nn.AdaptiveAvgPool3d(1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = torch.nn.Linear(128, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)  # Binary classification: motor presence\n",
    "        \n",
    "        # Regression head for 3D coordinates\n",
    "        self.reg = torch.nn.Linear(32, 3)\n",
    "        \n",
    "        # Activation and dropout\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the 3D CNN\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (Classification output, Regression output)\n",
    "        \"\"\"\n",
    "        # Initial convolutions\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        \n",
    "        # Apply attention\n",
    "        x = self.attention(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Classification output\n",
    "        cls_output = self.sigmoid(self.fc3(x))\n",
    "        \n",
    "        # Regression output (normalized coordinates)\n",
    "        reg_output = self.reg(x)\n",
    "        \n",
    "        return cls_output, reg_output\n",
    "    \n",
    "class Tomogram3DDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for 3D subvolumes extracted from tomograms\n",
    "    \"\"\"\n",
    "    def __init__(self, tomogram_dir, labels_df, subvolume_size=64, transform=None, train=True):\n",
    "        \"\"\"\n",
    "        Initialize the dataset\n",
    "        \n",
    "        Args:\n",
    "            tomogram_dir (str): Directory containing tomogram slice folders\n",
    "            labels_df (pd.DataFrame): DataFrame with motor annotations\n",
    "            subvolume_size (int): Size of cubic subvolume to extract\n",
    "            transform (callable, optional): Optional transform to apply to subvolumes\n",
    "            train (bool): Whether this is for training or inference\n",
    "        \"\"\"\n",
    "        self.tomogram_dir = tomogram_dir\n",
    "        self.labels_df = labels_df\n",
    "        self.subvolume_size = subvolume_size\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        \n",
    "        # Filter to tomograms with motors for training\n",
    "        if train:\n",
    "            self.motor_data = []\n",
    "            self.no_motor_data = []\n",
    "            \n",
    "            # First, collect all motors\n",
    "            for _, row in labels_df.iterrows():\n",
    "                if pd.isna(row['Motor axis 0']) or row['Motor axis 0'] <= 0:\n",
    "                    continue\n",
    "                    \n",
    "                tomo_id = row['tomo_id']\n",
    "                z = int(row['Motor axis 0'])\n",
    "                y = int(row['Motor axis 1'])\n",
    "                x = int(row['Motor axis 2'])\n",
    "                \n",
    "                self.motor_data.append({\n",
    "                    'tomo_id': tomo_id,\n",
    "                    'center': (z, y, x)\n",
    "                })\n",
    "            \n",
    "            # Then, collect random no-motor locations\n",
    "            for tomo_id in labels_df['tomo_id'].unique():\n",
    "                tomo_rows = labels_df[labels_df['tomo_id'] == tomo_id]\n",
    "                if tomo_rows['Number of motors'].iloc[0] == 0:\n",
    "                    # Get dimensions\n",
    "                    z_max = tomo_rows['Array shape (axis 0)'].iloc[0]\n",
    "                    y_max = tomo_rows['Array shape (axis 1)'].iloc[0]\n",
    "                    x_max = tomo_rows['Array shape (axis 2)'].iloc[0]\n",
    "                    \n",
    "                    # Generate random locations\n",
    "                    for _ in range(3):  # Add some negative samples per empty tomogram\n",
    "                        z = np.random.randint(subvolume_size//2, z_max - subvolume_size//2)\n",
    "                        y = np.random.randint(subvolume_size//2, y_max - subvolume_size//2)\n",
    "                        x = np.random.randint(subvolume_size//2, x_max - subvolume_size//2)\n",
    "                        \n",
    "                        self.no_motor_data.append({\n",
    "                            'tomo_id': tomo_id,\n",
    "                            'center': (z, y, x)\n",
    "                        })\n",
    "            \n",
    "            # Balance the dataset\n",
    "            if len(self.no_motor_data) > len(self.motor_data):\n",
    "                self.no_motor_data = random.sample(self.no_motor_data, len(self.motor_data))\n",
    "                \n",
    "            # Combine motor and no-motor data\n",
    "            self.samples = self.motor_data + self.no_motor_data\n",
    "            random.shuffle(self.samples)\n",
    "        else:\n",
    "            # For inference, we'll provide this dynamically\n",
    "            self.samples = []\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the number of samples in the dataset\n",
    "        \n",
    "        Returns:\n",
    "            int: Number of samples\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a sample from the dataset\n",
    "        \n",
    "        Args:\n",
    "            idx (int): Index of the sample\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (Subvolume, Motor presence, Coordinates)\n",
    "        \"\"\"\n",
    "        sample = self.samples[idx]\n",
    "        tomo_id = sample['tomo_id']\n",
    "        z, y, x = sample['center']\n",
    "        \n",
    "        # Extract subvolume\n",
    "        half_size = self.subvolume_size // 2\n",
    "        subvolume = np.zeros((self.subvolume_size, self.subvolume_size, self.subvolume_size), dtype=np.float32)\n",
    "        \n",
    "        # Load the slices\n",
    "        for i, z_pos in enumerate(range(z - half_size, z + half_size)):\n",
    "            if z_pos < 0:\n",
    "                continue\n",
    "                \n",
    "            slice_path = os.path.join(self.tomogram_dir, tomo_id, f\"slice_{z_pos:04d}.jpg\")\n",
    "            if not os.path.exists(slice_path):\n",
    "                continue\n",
    "                \n",
    "            # Load and normalize slice\n",
    "            img = np.array(Image.open(slice_path))\n",
    "            p2 = np.percentile(img, 2)\n",
    "            p98 = np.percentile(img, 98)\n",
    "            normalized = np.clip(img, p2, p98)\n",
    "            normalized = (normalized - p2) / (p98 - p2)\n",
    "            \n",
    "            # Extract region around center\n",
    "            y_start = max(0, y - half_size)\n",
    "            y_end = min(img.shape[0], y + half_size)\n",
    "            x_start = max(0, x - half_size)\n",
    "            x_end = min(img.shape[1], x + half_size)\n",
    "            \n",
    "            # Calculate target indices in subvolume\n",
    "            target_i = i\n",
    "            target_y_start = max(0, half_size - y)\n",
    "            target_x_start = max(0, half_size - x)\n",
    "            \n",
    "            # Calculate amount to copy\n",
    "            height = min(y_end - y_start, self.subvolume_size - target_y_start)\n",
    "            width = min(x_end - x_start, self.subvolume_size - target_x_start)\n",
    "            \n",
    "            if height <= 0 or width <= 0:\n",
    "                continue\n",
    "                \n",
    "            # Copy data\n",
    "            subvolume[target_i, \n",
    "                     target_y_start:target_y_start+height, \n",
    "                     target_x_start:target_x_start+width] = normalized[y_start:y_start+height, \n",
    "                                                                      x_start:x_start+width]\n",
    "        \n",
    "        # Prepare label\n",
    "        is_motor = 1.0 if sample in self.motor_data else 0.0\n",
    "        \n",
    "        # Normalize coordinates to [0, 1] for regression\n",
    "        if is_motor:\n",
    "            # Get tomogram dimensions for normalization\n",
    "            tomo_rows = self.labels_df[self.labels_df['tomo_id'] == tomo_id]\n",
    "            z_max = tomo_rows['Array shape (axis 0)'].iloc[0]\n",
    "            y_max = tomo_rows['Array shape (axis 1)'].iloc[0]\n",
    "            x_max = tomo_rows['Array shape (axis 2)'].iloc[0]\n",
    "            \n",
    "            # Normalize coordinates\n",
    "            coords = torch.tensor([z / z_max, y / y_max, x / x_max], dtype=torch.float32)\n",
    "        else:\n",
    "            coords = torch.zeros(3, dtype=torch.float32)\n",
    "        \n",
    "        # Apply transform if provided\n",
    "        if self.transform:\n",
    "            subvolume = self.transform(subvolume)\n",
    "        \n",
    "        # Add channel dimension\n",
    "        subvolume = torch.tensor(subvolume).unsqueeze(0).float()\n",
    "        \n",
    "        return subvolume, torch.tensor([is_motor]).float(), coords\n",
    "    \n",
    "    def extract_candidate_subvolumes(self, tomo_id, slice_indices, confidence_map):\n",
    "        \"\"\"\n",
    "        Extract candidate subvolumes based on 2D YOLO detections\n",
    "        \n",
    "        Args:\n",
    "            tomo_id (str): Tomogram ID\n",
    "            slice_indices (list): List of slice indices\n",
    "            confidence_map (dict): Dictionary mapping slice index to list of (y, x, conf) detections\n",
    "            \n",
    "        Returns:\n",
    "            list: List of (subvolume, z, y, x, conf) tuples\n",
    "        \"\"\"\n",
    "        candidates = []\n",
    "        \n",
    "        # Get tomogram dimensions\n",
    "        tomo_rows = self.labels_df[self.labels_df['tomo_id'] == tomo_id]\n",
    "        if tomo_rows.empty:\n",
    "            # For test tomograms where we don't have labels\n",
    "            # We'll need to get dimensions from the images\n",
    "            tomo_dir = os.path.join(self.tomogram_dir, tomo_id)\n",
    "            slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
    "            z_max = len(slice_files)\n",
    "            if z_max == 0:\n",
    "                return candidates\n",
    "                \n",
    "            sample_img = np.array(Image.open(os.path.join(tomo_dir, slice_files[0])))\n",
    "            y_max, x_max = sample_img.shape\n",
    "        else:\n",
    "            z_max = tomo_rows['Array shape (axis 0)'].iloc[0]\n",
    "            y_max = tomo_rows['Array shape (axis 1)'].iloc[0]\n",
    "            x_max = tomo_rows['Array shape (axis 2)'].iloc[0]\n",
    "        \n",
    "        # Extract top candidates from each slice\n",
    "        for z in slice_indices:\n",
    "            if z not in confidence_map:\n",
    "                continue\n",
    "                \n",
    "            # Get top detections for this slice\n",
    "            detections = confidence_map[z]\n",
    "            for y, x, conf in detections:\n",
    "                # Skip if too close to edge\n",
    "                half_size = self.subvolume_size // 2\n",
    "                if (z < half_size or z >= z_max - half_size or\n",
    "                    y < half_size or y >= y_max - half_size or\n",
    "                    x < half_size or x >= x_max - half_size):\n",
    "                    continue\n",
    "                \n",
    "                # Extract subvolume\n",
    "                subvolume = np.zeros((self.subvolume_size, self.subvolume_size, self.subvolume_size), dtype=np.float32)\n",
    "                \n",
    "                # Load slices\n",
    "                for i, z_pos in enumerate(range(z - half_size, z + half_size)):\n",
    "                    slice_path = os.path.join(self.tomogram_dir, tomo_id, f\"slice_{z_pos:04d}.jpg\")\n",
    "                    if not os.path.exists(slice_path):\n",
    "                        continue\n",
    "                        \n",
    "                    # Load and normalize slice\n",
    "                    img = np.array(Image.open(slice_path))\n",
    "                    p2 = np.percentile(img, 2)\n",
    "                    p98 = np.percentile(img, 98)\n",
    "                    normalized = np.clip(img, p2, p98)\n",
    "                    normalized = (normalized - p2) / (p98 - p2)\n",
    "                    \n",
    "                    # Extract region around center\n",
    "                    y_start = max(0, int(y) - half_size)\n",
    "                    y_end = min(img.shape[0], int(y) + half_size)\n",
    "                    x_start = max(0, int(x) - half_size)\n",
    "                    x_end = min(img.shape[1], int(x) + half_size)\n",
    "                    \n",
    "                    # Calculate target indices in subvolume\n",
    "                    target_i = i\n",
    "                    target_y_start = max(0, half_size - int(y))\n",
    "                    target_x_start = max(0, half_size - int(x))\n",
    "                    \n",
    "                    # Calculate amount to copy\n",
    "                    height = min(y_end - y_start, self.subvolume_size - target_y_start)\n",
    "                    width = min(x_end - x_start, self.subvolume_size - target_x_start)\n",
    "                    \n",
    "                    if height <= 0 or width <= 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # Copy data\n",
    "                    subvolume[target_i, \n",
    "                              target_y_start:target_y_start+height, \n",
    "                              target_x_start:target_x_start+width] = normalized[y_start:y_start+height, \n",
    "                                                                              x_start:x_start+width]\n",
    "                \n",
    "                # Add channel dimension\n",
    "                subvolume = torch.tensor(subvolume).unsqueeze(0).float()\n",
    "                candidates.append((subvolume, z, y, x, conf))\n",
    "        \n",
    "        return candidates\n",
    "    \n",
    "class Motor3DCNNTrainer:\n",
    "    \"\"\"\n",
    "    Trainer for the 3D CNN model\n",
    "    \"\"\"\n",
    "    def __init__(self, train_dir, labels_df, working_dir, subvolume_size=64, batch_size=8, device='auto'):\n",
    "        \"\"\"\n",
    "        Initialize the trainer\n",
    "        \n",
    "        Args:\n",
    "            train_dir (str): Directory containing training tomograms\n",
    "            labels_df (pd.DataFrame): DataFrame with motor annotations\n",
    "            working_dir (str): Directory for saving models and results\n",
    "            subvolume_size (int): Size of cubic subvolumes\n",
    "            batch_size (int): Training batch size\n",
    "            device (str): Device to use ('cpu', 'cuda', or 'auto')\n",
    "        \"\"\"\n",
    "        self.train_dir = train_dir\n",
    "        self.labels_df = labels_df\n",
    "        self.working_dir = working_dir\n",
    "        self.subvolume_size = subvolume_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Set device\n",
    "        if device == 'auto':\n",
    "            self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "            \n",
    "        print(f\"Using device: {self.device} for 3D CNN\")\n",
    "        \n",
    "        # Create model directory\n",
    "        self.model_dir = os.path.join(working_dir, '3dcnn_models')\n",
    "        os.makedirs(self.model_dir, exist_ok=True)\n",
    "        \n",
    "    def train(self, epochs=20, lr=1e-4, dropout=0.3):\n",
    "        \"\"\"\n",
    "        Train the 3D CNN model\n",
    "        \n",
    "        Args:\n",
    "            epochs (int): Number of training epochs\n",
    "            lr (float): Learning rate\n",
    "            dropout (float): Dropout rate\n",
    "            \n",
    "        Returns:\n",
    "            torch.nn.Module: Trained model\n",
    "        \"\"\"\n",
    "        # Create dataset\n",
    "        dataset = Tomogram3DDataset(\n",
    "            tomogram_dir=self.train_dir,\n",
    "            labels_df=self.labels_df,\n",
    "            subvolume_size=self.subvolume_size,\n",
    "            train=True\n",
    "        )\n",
    "        \n",
    "        # Split dataset into train and validation\n",
    "        train_size = int(0.8 * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4\n",
    "        )\n",
    "        \n",
    "        # Create model\n",
    "        model = Motor3DCNN(input_channels=1, dropout_rate=dropout)\n",
    "        model.to(self.device)\n",
    "        \n",
    "        # Define loss functions\n",
    "        cls_criterion = torch.nn.BCELoss()\n",
    "        reg_criterion = torch.nn.MSELoss()\n",
    "        \n",
    "        # Create optimizer\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # Create learning rate scheduler\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min', \n",
    "            factor=0.5, \n",
    "            patience=3, \n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Training loop\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_path = os.path.join(self.model_dir, '3dcnn_best.pt')\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_cls_loss = 0.0\n",
    "            train_reg_loss = 0.0\n",
    "            \n",
    "            for subvolumes, labels, coords in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} (Train)\"):\n",
    "                # Move data to device\n",
    "                subvolumes = subvolumes.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                coords = coords.to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                optimizer.zero_grad()\n",
    "                cls_output, reg_output = model(subvolumes)\n",
    "                \n",
    "                # Compute losses\n",
    "                # For regression loss, only consider positive samples\n",
    "                pos_mask = (labels > 0.5).view(-1)\n",
    "                cls_loss = cls_criterion(cls_output, labels)\n",
    "                \n",
    "                # Only compute regression loss for positive samples\n",
    "                if torch.sum(pos_mask) > 0:\n",
    "                    reg_loss = reg_criterion(reg_output[pos_mask], coords[pos_mask])\n",
    "                else:\n",
    "                    reg_loss = torch.tensor(0.0, device=self.device)\n",
    "                \n",
    "                # Total loss (weighted sum)\n",
    "                loss = cls_loss + 0.5 * reg_loss\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Update metrics\n",
    "                train_loss += loss.item() * subvolumes.size(0)\n",
    "                train_cls_loss += cls_loss.item() * subvolumes.size(0)\n",
    "                train_reg_loss += reg_loss.item() * subvolumes.size(0)\n",
    "            \n",
    "            # Calculate average losses\n",
    "            train_loss /= len(train_loader.dataset)\n",
    "            train_cls_loss /= len(train_loader.dataset)\n",
    "            train_reg_loss /= len(train_loader.dataset)\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_cls_loss = 0.0\n",
    "            val_reg_loss = 0.0\n",
    "            correct_preds = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for subvolumes, labels, coords in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} (Val)\"):\n",
    "                    # Move data to device\n",
    "                    subvolumes = subvolumes.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "                    coords = coords.to(self.device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    cls_output, reg_output = model(subvolumes)\n",
    "                    \n",
    "                    # Compute losses\n",
    "                    pos_mask = (labels > 0.5).view(-1)\n",
    "                    cls_loss = cls_criterion(cls_output, labels)\n",
    "                    \n",
    "                    if torch.sum(pos_mask) > 0:\n",
    "                        reg_loss = reg_criterion(reg_output[pos_mask], coords[pos_mask])\n",
    "                    else:\n",
    "                        reg_loss = torch.tensor(0.0, device=self.device)\n",
    "                    \n",
    "                    loss = cls_loss + 0.5 * reg_loss\n",
    "                    \n",
    "                    # Update metrics\n",
    "                    val_loss += loss.item() * subvolumes.size(0)\n",
    "                    val_cls_loss += cls_loss.item() * subvolumes.size(0)\n",
    "                    val_reg_loss += reg_loss.item() * subvolumes.size(0)\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    preds = (cls_output > 0.5).float()\n",
    "                    correct_preds += torch.sum(preds == labels).item()\n",
    "            \n",
    "            # Calculate average validation losses\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            val_cls_loss /= len(val_loader.dataset)\n",
    "            val_reg_loss /= len(val_loader.dataset)\n",
    "            val_acc = correct_preds / len(val_loader.dataset)\n",
    "            \n",
    "            # Update learning rate\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # Print progress\n",
    "            print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f} (Cls: {train_cls_loss:.4f}, Reg: {train_reg_loss:.4f})\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f} (Cls: {val_cls_loss:.4f}, Reg: {val_reg_loss:.4f}), Acc: {val_acc:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(f\"  New best model saved to {best_model_path}\")\n",
    "        \n",
    "        # Load best model\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "        \n",
    "        return model\n",
    "\n",
    "# Phase 2: Train the 3D CNN model\n",
    "print(\"\\nTraining 3D CNN model...\")\n",
    "cnn3d_trainer = Motor3DCNNTrainer(\n",
    "    train_dir=TRAIN_DIR,\n",
    "    labels_df=train_labels,\n",
    "    working_dir=WORKING_DIR,\n",
    "    subvolume_size=64,\n",
    "    batch_size=4,\n",
    "    device='auto'\n",
    ")\n",
    "\n",
    "# Train the 3D CNN model\n",
    "cnn3d_model = cnn3d_trainer.train(epochs=20, lr=1e-4, dropout=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference Pipeline for Test Data\n",
    "\n",
    "An efficient inference pipeline to process test tomograms and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EnsembleMotorDetector:\n",
    "    \"\"\"\n",
    "    Ensemble detector combining 2D YOLOv8 and 3D CNN for improved motor detection\n",
    "    \"\"\"\n",
    "    def __init__(self, yolo_model_path, cnn3d_model_path, test_dir, submission_path, \n",
    "                 device='auto', yolo_confidence_threshold=0.30, cnn_confidence_threshold=0.45):\n",
    "        \"\"\"\n",
    "        Initialize the detector with both YOLO and 3D CNN models\n",
    "        \n",
    "        Args:\n",
    "            yolo_model_path (str): Path to trained YOLO model weights\n",
    "            cnn3d_model_path (str): Path to trained 3D CNN model weights\n",
    "            test_dir (str): Path to test tomograms directory\n",
    "            submission_path (str): Path to save submission CSV\n",
    "            device (str): Device to use ('cpu', 'cuda', or 'auto')\n",
    "            yolo_confidence_threshold (float): Confidence threshold for YOLO detections\n",
    "            cnn_confidence_threshold (float): Confidence threshold for 3D CNN detections\n",
    "        \"\"\"\n",
    "        self.yolo_model_path = yolo_model_path\n",
    "        self.cnn3d_model_path = cnn3d_model_path\n",
    "        self.test_dir = test_dir\n",
    "        self.submission_path = submission_path\n",
    "        self.yolo_confidence_threshold = yolo_confidence_threshold\n",
    "        self.cnn_confidence_threshold = cnn_confidence_threshold\n",
    "        \n",
    "        # Set device\n",
    "        if device == 'auto':\n",
    "            self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "            \n",
    "        print(f\"Using device: {self.device} for ensemble detection\")\n",
    "        \n",
    "        # Detection parameters\n",
    "        self.nms_iou_threshold = 0.2  # Non-maximum suppression threshold\n",
    "        self.batch_size = 8  # Default batch size, will be adjusted dynamically\n",
    "        self.concentration = 1.0  # Process all slices (can be reduced for faster testing)\n",
    "        self.subvolume_size = 64  # Size of 3D CNN input subvolumes\n",
    "    \n",
    "    def load_models(self):\n",
    "        \"\"\"\n",
    "        Load both YOLO and 3D CNN models\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (YOLO model, 3D CNN model)\n",
    "        \"\"\"\n",
    "        # Load YOLO model\n",
    "        print(f\"Loading YOLO model from {self.yolo_model_path}\")\n",
    "        yolo_model = YOLO(self.yolo_model_path)\n",
    "        yolo_model.to(self.device)\n",
    "        \n",
    "        # Fuse layers for faster inference if using GPU\n",
    "        if self.device.startswith('cuda'):\n",
    "            yolo_model.fuse()\n",
    "            \n",
    "            # Use half precision if on compatible GPU\n",
    "            if torch.cuda.get_device_capability(0)[0] >= 7:  # Volta or newer\n",
    "                yolo_model.model.half()\n",
    "                print(\"Using half precision (FP16) for YOLO inference\")\n",
    "                \n",
    "            # Get available GPU memory and set batch size accordingly\n",
    "            free_mem = torch.cuda.get_device_properties(0).total_memory / 1e9 - torch.cuda.memory_allocated(0) / 1e9\n",
    "            self.batch_size = max(4, min(32, int(free_mem * 4)))  # 4 images per GB as rough estimate\n",
    "            print(f\"Dynamic batch size set to {self.batch_size} based on available GPU memory\")\n",
    "        \n",
    "        # Load 3D CNN model\n",
    "        print(f\"Loading 3D CNN model from {self.cnn3d_model_path}\")\n",
    "        cnn3d_model = Motor3DCNN(input_channels=1, dropout_rate=0.0)  # No dropout for inference\n",
    "        cnn3d_model.load_state_dict(torch.load(self.cnn3d_model_path, map_location=self.device))\n",
    "        cnn3d_model.to(self.device)\n",
    "        cnn3d_model.eval()  # Set to evaluation mode\n",
    "        \n",
    "        return yolo_model, cnn3d_model\n",
    "    \n",
    "    def preload_image_batch(self, file_paths):\n",
    "        \"\"\"\n",
    "        Preload a batch of images to CPU memory\n",
    "        \n",
    "        Args:\n",
    "            file_paths (list): List of file paths to load\n",
    "            \n",
    "        Returns:\n",
    "            list: List of loaded images\n",
    "        \"\"\"\n",
    "        images = []\n",
    "        for path in file_paths:\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                # Try with PIL as fallback\n",
    "                img = np.array(Image.open(path))\n",
    "            images.append(img)\n",
    "        return images\n",
    "    \n",
    "    def perform_3d_nms(self, detections, iou_threshold):\n",
    "        \"\"\"\n",
    "        Perform 3D Non-Maximum Suppression on detections\n",
    "        \n",
    "        Args:\n",
    "            detections (list): List of detection dictionaries\n",
    "            iou_threshold (float): IoU threshold for suppression\n",
    "            \n",
    "        Returns:\n",
    "            list: Filtered detections after NMS\n",
    "        \"\"\"\n",
    "        if not detections:\n",
    "            return []\n",
    "        \n",
    "        # Sort by confidence (highest first)\n",
    "        detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n",
    "        \n",
    "        # List to store final detections after NMS\n",
    "        final_detections = []\n",
    "        \n",
    "        # Define 3D distance function\n",
    "        def distance_3d(d1, d2):\n",
    "            return np.sqrt((d1['z'] - d2['z'])**2 + \n",
    "                          (d1['y'] - d2['y'])**2 + \n",
    "                          (d1['x'] - d2['x'])**2)\n",
    "        \n",
    "        # Maximum distance threshold (based on box size)\n",
    "        box_size = 24  # Same as annotation box size\n",
    "        distance_threshold = box_size * iou_threshold\n",
    "        \n",
    "        # Process each detection\n",
    "        while detections:\n",
    "            # Take the detection with highest confidence\n",
    "            best_detection = detections.pop(0)\n",
    "            final_detections.append(best_detection)\n",
    "            \n",
    "            # Filter out detections that are too close to the best detection\n",
    "            detections = [d for d in detections if distance_3d(d, best_detection) > distance_threshold]\n",
    "        \n",
    "        return final_detections\n",
    "    \n",
    "    def extract_subvolume(self, tomo_id, z, y, x):\n",
    "        \"\"\"\n",
    "        Extract a subvolume centered at the given coordinates\n",
    "        \n",
    "        Args:\n",
    "            tomo_id (str): Tomogram ID\n",
    "            z (int): Z coordinate\n",
    "            y (int): Y coordinate\n",
    "            x (int): X coordinate\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Extracted subvolume as a tensor with shape [1, 1, D, H, W]\n",
    "        \"\"\"\n",
    "        half_size = self.subvolume_size // 2\n",
    "        subvolume = np.zeros((self.subvolume_size, self.subvolume_size, self.subvolume_size), dtype=np.float32)\n",
    "        tomo_dir = os.path.join(self.test_dir, tomo_id)\n",
    "        \n",
    "        # Load the slices\n",
    "        for i, z_pos in enumerate(range(z - half_size, z + half_size)):\n",
    "            if z_pos < 0:\n",
    "                continue\n",
    "                \n",
    "            slice_path = os.path.join(tomo_dir, f\"slice_{z_pos:04d}.jpg\")\n",
    "            if not os.path.exists(slice_path):\n",
    "                continue\n",
    "                \n",
    "            # Load and normalize slice\n",
    "            img = np.array(Image.open(slice_path))\n",
    "            \n",
    "            # Normalize using our adaptive method\n",
    "            p2 = np.percentile(img, 2)\n",
    "            p98 = np.percentile(img, 98)\n",
    "            normalized = np.clip(img, p2, p98)\n",
    "            normalized = (normalized - p2) / (p98 - p2)\n",
    "            \n",
    "            # Convert to float32 for processing\n",
    "            normalized = normalized.astype(np.float32)\n",
    "            \n",
    "            # Extract region around center\n",
    "            y_start = max(0, y - half_size)\n",
    "            y_end = min(img.shape[0], y + half_size)\n",
    "            x_start = max(0, x - half_size)\n",
    "            x_end = min(img.shape[1], x + half_size)\n",
    "            \n",
    "            # Calculate target indices in subvolume\n",
    "            target_i = i\n",
    "            target_y_start = max(0, half_size - (y - y_start))\n",
    "            target_x_start = max(0, half_size - (x - x_start))\n",
    "            \n",
    "            # Calculate amount to copy\n",
    "            height = min(y_end - y_start, self.subvolume_size - target_y_start)\n",
    "            width = min(x_end - x_start, self.subvolume_size - target_x_start)\n",
    "            \n",
    "            if height <= 0 or width <= 0:\n",
    "                continue\n",
    "                \n",
    "            # Copy data\n",
    "            subvolume[target_i, \n",
    "                     target_y_start:target_y_start+height, \n",
    "                     target_x_start:target_x_start+width] = normalized[y_start:y_start+height, \n",
    "                                                                      x_start:x_start+width]\n",
    "        \n",
    "        # Add batch and channel dimensions to create a 5D tensor [B, C, D, H, W]\n",
    "        # This is the fix for the \"expected 5D input (got 4D input)\" error\n",
    "        subvolume_tensor = torch.tensor(subvolume).float()\n",
    "        subvolume_tensor = subvolume_tensor.unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n",
    "        \n",
    "        return subvolume_tensor\n",
    "    \n",
    "    def process_tomogram(self, tomo_id, yolo_model, cnn3d_model, index=0, total=1):\n",
    "        \"\"\"\n",
    "        Process a single tomogram using both YOLO and 3D CNN models\n",
    "        \n",
    "        Args:\n",
    "            tomo_id (str): Tomogram ID\n",
    "            yolo_model: YOLO model\n",
    "            cnn3d_model: 3D CNN model\n",
    "            index (int): Current tomogram index\n",
    "            total (int): Total number of tomograms\n",
    "            \n",
    "        Returns:\n",
    "            dict: Detection result with coordinates\n",
    "        \"\"\"\n",
    "        print(f\"Processing tomogram {tomo_id} ({index}/{total})\")\n",
    "        \n",
    "        # Get all slice files for this tomogram\n",
    "        tomo_dir = os.path.join(self.test_dir, tomo_id)\n",
    "        slice_files = sorted([f for f in os.listdir(tomo_dir) if f.endswith('.jpg')])\n",
    "        \n",
    "        # Apply concentration if needed\n",
    "        if self.concentration < 1.0:\n",
    "            selected_indices = np.linspace(0, len(slice_files)-1, int(len(slice_files) * self.concentration))\n",
    "            selected_indices = np.round(selected_indices).astype(int)\n",
    "            slice_files = [slice_files[i] for i in selected_indices]\n",
    "            print(f\"Processing {len(slice_files)} out of {len(os.listdir(tomo_dir))} slices\")\n",
    "        \n",
    "        # STEP 1: Run YOLO on 2D slices to get candidates\n",
    "        print(\"STEP 1: Running YOLO detection on 2D slices...\")\n",
    "        yolo_detections = []\n",
    "        \n",
    "        # Create CUDA streams for parallel processing\n",
    "        if self.device.startswith('cuda'):\n",
    "            streams = [torch.cuda.Stream() for _ in range(min(4, self.batch_size))]\n",
    "        else:\n",
    "            streams = [None]\n",
    "        \n",
    "        # Variables for preloading\n",
    "        next_batch_thread = None\n",
    "        next_batch_images = None\n",
    "        \n",
    "        # Process slices in batches\n",
    "        for batch_start in range(0, len(slice_files), self.batch_size):\n",
    "            # Wait for previous preload thread if it exists\n",
    "            if next_batch_thread is not None:\n",
    "                next_batch_thread.join()\n",
    "                next_batch_images = None\n",
    "                \n",
    "            batch_end = min(batch_start + self.batch_size, len(slice_files))\n",
    "            batch_files = slice_files[batch_start:batch_end]\n",
    "            \n",
    "            # Start preloading next batch\n",
    "            next_batch_start = batch_end\n",
    "            next_batch_end = min(next_batch_start + self.batch_size, len(slice_files))\n",
    "            next_batch_files = slice_files[next_batch_start:next_batch_end] if next_batch_start < len(slice_files) else []\n",
    "            \n",
    "            if next_batch_files:\n",
    "                next_batch_paths = [os.path.join(tomo_dir, f) for f in next_batch_files]\n",
    "                next_batch_thread = threading.Thread(target=self.preload_image_batch, args=(next_batch_paths,))\n",
    "                next_batch_thread.start()\n",
    "            else:\n",
    "                next_batch_thread = None\n",
    "            \n",
    "            # Split batch across streams for parallel processing\n",
    "            sub_batches = np.array_split(batch_files, len(streams))\n",
    "            \n",
    "            for i, sub_batch in enumerate(sub_batches):\n",
    "                if len(sub_batch) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                stream = streams[i % len(streams)]\n",
    "                with torch.cuda.stream(stream) if stream and self.device.startswith('cuda') else nullcontext():\n",
    "                    # Process sub-batch\n",
    "                    sub_batch_paths = [os.path.join(tomo_dir, slice_file) for slice_file in sub_batch]\n",
    "                    sub_batch_slice_nums = [int(slice_file.split('_')[1].split('.')[0]) for slice_file in sub_batch]\n",
    "                    \n",
    "                    # Run inference\n",
    "                    sub_results = yolo_model(sub_batch_paths, verbose=False)\n",
    "                    \n",
    "                    # Process each result in this sub-batch\n",
    "                    for j, result in enumerate(sub_results):\n",
    "                        if len(result.boxes) > 0:\n",
    "                            boxes = result.boxes\n",
    "                            for box_idx, confidence in enumerate(boxes.conf):\n",
    "                                if confidence >= self.yolo_confidence_threshold:\n",
    "                                    # Get bounding box coordinates\n",
    "                                    x1, y1, x2, y2 = boxes.xyxy[box_idx].cpu().numpy()\n",
    "                                    \n",
    "                                    # Calculate center coordinates\n",
    "                                    x_center = (x1 + x2) / 2\n",
    "                                    y_center = (y1 + y2) / 2\n",
    "                                    \n",
    "                                    # Store detection with 3D coordinates\n",
    "                                    yolo_detections.append({\n",
    "                                        'z': round(sub_batch_slice_nums[j]),\n",
    "                                        'y': round(y_center),\n",
    "                                        'x': round(x_center),\n",
    "                                        'confidence': float(confidence),\n",
    "                                        'model': 'yolo'\n",
    "                                    })\n",
    "            \n",
    "            # Synchronize streams\n",
    "            if self.device.startswith('cuda'):\n",
    "                torch.cuda.synchronize()\n",
    "        \n",
    "        # Clean up thread if still running\n",
    "        if next_batch_thread is not None:\n",
    "            next_batch_thread.join()\n",
    "        \n",
    "        # Apply 3D NMS to consolidate YOLO detections\n",
    "        yolo_detections = self.perform_3d_nms(yolo_detections, self.nms_iou_threshold)\n",
    "        print(f\"YOLO found {len(yolo_detections)} potential candidates\")\n",
    "        \n",
    "        # If no YOLO detections, return early\n",
    "        if not yolo_detections:\n",
    "            return {\n",
    "                'tomo_id': tomo_id,\n",
    "                'Motor axis 0': -1,\n",
    "                'Motor axis 1': -1,\n",
    "                'Motor axis 2': -1\n",
    "            }\n",
    "        \n",
    "        # STEP 2: Validate candidates with 3D CNN\n",
    "        print(\"STEP 2: Validating candidates with 3D CNN...\")\n",
    "        validated_detections = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for detection in yolo_detections[:min(10, len(yolo_detections))]:  # Process top candidates\n",
    "                z, y, x = detection['z'], detection['y'], detection['x']\n",
    "                \n",
    "                # Skip if too close to edge for 3D CNN processing\n",
    "                half_size = self.subvolume_size // 2\n",
    "                slice_sample = os.path.join(tomo_dir, slice_files[0])\n",
    "                try:\n",
    "                    tomo_shape = np.array(Image.open(slice_sample)).shape\n",
    "                    if (z < half_size or z >= len(slice_files) - half_size or\n",
    "                        y < half_size or y >= tomo_shape[0] - half_size or\n",
    "                        x < half_size or x >= tomo_shape[1] - half_size):\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract subvolume with proper 5D shape [B, C, D, H, W]\n",
    "                    subvolume = self.extract_subvolume(tomo_id, z, y, x)\n",
    "                    subvolume = subvolume.to(self.device)\n",
    "                    \n",
    "                    # Run 3D CNN inference\n",
    "                    cls_output, reg_output = cnn3d_model(subvolume)\n",
    "                    \n",
    "                    # Check if 3D CNN confirms the detection\n",
    "                    if cls_output.item() >= self.cnn_confidence_threshold:\n",
    "                        # Add to validated detections\n",
    "                        validated_detections.append({\n",
    "                            'z': z,\n",
    "                            'y': y,\n",
    "                            'x': x,\n",
    "                            'yolo_confidence': detection['confidence'],\n",
    "                            'cnn_confidence': cls_output.item(),\n",
    "                            'ensemble_confidence': (detection['confidence'] + cls_output.item()) / 2,\n",
    "                            'model': 'ensemble'\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing candidate at z={z}, y={y}, x={x}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        print(f\"3D CNN validated {len(validated_detections)} candidates\")\n",
    "        \n",
    "        # STEP 3: Make final prediction using ensemble\n",
    "        if validated_detections:\n",
    "            # Sort by ensemble confidence\n",
    "            validated_detections.sort(key=lambda x: x['ensemble_confidence'], reverse=True)\n",
    "            best_detection = validated_detections[0]\n",
    "            \n",
    "            # Return the best ensemble detection\n",
    "            return {\n",
    "                'tomo_id': tomo_id,\n",
    "                'Motor axis 0': round(best_detection['z']),\n",
    "                'Motor axis 1': round(best_detection['y']),\n",
    "                'Motor axis 2': round(best_detection['x'])\n",
    "            }\n",
    "        else:\n",
    "            # If no validated detections, fall back to best YOLO detection\n",
    "            best_yolo = max(yolo_detections, key=lambda x: x['confidence'])\n",
    "            \n",
    "            # Only use YOLO if it's very confident\n",
    "            if best_yolo['confidence'] > 0.65:\n",
    "                return {\n",
    "                    'tomo_id': tomo_id,\n",
    "                    'Motor axis 0': round(best_yolo['z']),\n",
    "                    'Motor axis 1': round(best_yolo['y']),\n",
    "                    'Motor axis 2': round(best_yolo['x'])\n",
    "                }\n",
    "            else:\n",
    "                # Otherwise, say no motor found\n",
    "                return {\n",
    "                    'tomo_id': tomo_id,\n",
    "                    'Motor axis 0': -1,\n",
    "                    'Motor axis 1': -1,\n",
    "                    'Motor axis 2': -1\n",
    "                }\n",
    "    \n",
    "    def generate_submission(self):\n",
    "        \"\"\"\n",
    "        Process all test tomograms using the ensemble approach and generate submission\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Submission dataframe\n",
    "        \"\"\"\n",
    "        # Get list of test tomograms\n",
    "        test_tomos = sorted([d for d in os.listdir(self.test_dir) if os.path.isdir(os.path.join(self.test_dir, d))])\n",
    "        total_tomos = len(test_tomos)\n",
    "        \n",
    "        print(f\"Found {total_tomos} tomograms in test directory\")\n",
    "        \n",
    "        # Clear GPU cache before starting\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Load models\n",
    "        yolo_model, cnn3d_model = self.load_models()\n",
    "        \n",
    "        # Process tomograms with parallelization\n",
    "        results = []\n",
    "        motors_found = 0\n",
    "        \n",
    "        # Using ThreadPoolExecutor with max_workers=1 since each worker uses the GPU\n",
    "        # and we're parallelizing within each tomogram processing\n",
    "        with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "            future_to_tomo = {}\n",
    "            \n",
    "            # Submit all tomograms for processing\n",
    "            for i, tomo_id in enumerate(test_tomos, 1):\n",
    "                future = executor.submit(self.process_tomogram, tomo_id, yolo_model, cnn3d_model, i, total_tomos)\n",
    "                future_to_tomo[future] = tomo_id\n",
    "            \n",
    "            # Process completed futures as they complete\n",
    "            for future in future_to_tomo:\n",
    "                tomo_id = future_to_tomo[future]\n",
    "                try:\n",
    "                    # Clear CUDA cache between tomograms\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "                    result = future.result()\n",
    "                    results.append(result)\n",
    "                    \n",
    "                    # Update motors found count\n",
    "                    motor_found = result['Motor axis 0'] != -1\n",
    "                    if motor_found:\n",
    "                        motors_found += 1\n",
    "                        print(f\"Motor found in {tomo_id} at position: \"\n",
    "                              f\"z={result['Motor axis 0']}, y={result['Motor axis 1']}, x={result['Motor axis 2']}\")\n",
    "                    else:\n",
    "                        print(f\"No motor detected in {tomo_id}\")\n",
    "                        \n",
    "                    print(f\"Current detection rate: {motors_found}/{len(results)} ({motors_found/len(results)*100:.1f}%)\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {tomo_id}: {e}\")\n",
    "                    # Create a default entry for failed tomograms\n",
    "                    results.append({\n",
    "                        'tomo_id': tomo_id,\n",
    "                        'Motor axis 0': -1,\n",
    "                        'Motor axis 1': -1,\n",
    "                        'Motor axis 2': -1\n",
    "                    })\n",
    "        \n",
    "        # Create submission dataframe\n",
    "        submission_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Ensure proper column order\n",
    "        submission_df = submission_df[['tomo_id', 'Motor axis 0', 'Motor axis 1', 'Motor axis 2']]\n",
    "        \n",
    "        # Save the submission file\n",
    "        submission_df.to_csv(self.submission_path, index=False)\n",
    "        \n",
    "        print(f\"\\nSubmission complete!\")\n",
    "        print(f\"Motors detected: {motors_found}/{total_tomos} ({motors_found/total_tomos*100:.1f}%)\")\n",
    "        print(f\"Submission saved to: {self.submission_path}\")\n",
    "        \n",
    "        # Display first few rows of submission\n",
    "        print(\"\\nSubmission preview:\")\n",
    "        print(submission_df.head())\n",
    "        \n",
    "        return submission_df\n",
    "\n",
    "# Paths to trained model weights\n",
    "yolo_model_path = os.path.join(WORKING_DIR, \"yolo_weights\", \"motor_detector\", \"weights\", \"best.pt\")\n",
    "cnn3d_model_path = os.path.join(WORKING_DIR, \"3dcnn_models\", \"3dcnn_best.pt\")\n",
    "\n",
    "# Create the ensemble motor detector\n",
    "ensemble_detector = EnsembleMotorDetector(\n",
    "    yolo_model_path=yolo_model_path,\n",
    "    cnn3d_model_path=cnn3d_model_path,\n",
    "    test_dir=TEST_DIR,\n",
    "    submission_path=os.path.join(WORKING_DIR, \"ensemble_submission.csv\"),\n",
    "    device='auto',\n",
    "    yolo_confidence_threshold=0.30,  # Slightly lower threshold to catch more candidates\n",
    "    cnn_confidence_threshold=0.45    # Then filter with 3D CNN\n",
    ")\n",
    "\n",
    "# Generate the ensemble submission\n",
    "ensemble_submission = ensemble_detector.generate_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Visualization and Analysis\n",
    "\n",
    "Visualize predictions to understand how our model is performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_detection(tomo_id, coordinates, test_dir, context_slices=2):\n",
    "    \"\"\"\n",
    "    Visualize a motor detection with context slices\n",
    "    \n",
    "    Args:\n",
    "        tomo_id (str): Tomogram ID\n",
    "        coordinates (dict): Dictionary with motor coordinates\n",
    "        test_dir (str): Test directory path\n",
    "        context_slices (int): Number of context slices to show\n",
    "    \"\"\"\n",
    "    z_center = coordinates['Motor axis 0']\n",
    "    y_center = coordinates['Motor axis 1']\n",
    "    x_center = coordinates['Motor axis 2']\n",
    "    \n",
    "    # If no motor detected, show message\n",
    "    if z_center == -1:\n",
    "        print(f\"No motor detected in tomogram {tomo_id}\")\n",
    "        return\n",
    "    \n",
    "    # Get slices\n",
    "    tomo_dir = os.path.join(test_dir, tomo_id)\n",
    "    \n",
    "    # Calculate slice range\n",
    "    z_min = max(0, z_center - context_slices)\n",
    "    z_max = z_center + context_slices\n",
    "    \n",
    "    # Get list of slices in this range\n",
    "    slices = []\n",
    "    for z in range(z_min, z_max + 1):\n",
    "        slice_path = os.path.join(tomo_dir, f\"slice_{z:04d}.jpg\")\n",
    "        if os.path.exists(slice_path):\n",
    "            img = np.array(Image.open(slice_path))\n",
    "            # Normalize for better visibility\n",
    "            p2 = np.percentile(img, 2)\n",
    "            p98 = np.percentile(img, 98)\n",
    "            normalized = np.clip(img, p2, p98)\n",
    "            normalized = 255 * (normalized - p2) / (p98 - p2)\n",
    "            normalized = np.uint8(normalized)\n",
    "            slices.append((z, normalized))\n",
    "    \n",
    "    # Create figure\n",
    "    n_slices = len(slices)\n",
    "    fig, axes = plt.subplots(1, n_slices, figsize=(4*n_slices, 4))\n",
    "    \n",
    "    if n_slices == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Display each slice\n",
    "    for i, (z, img) in enumerate(slices):\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(f\"Slice z={z}\")\n",
    "        \n",
    "        # Draw bounding box on the motor slice\n",
    "        if z == z_center:\n",
    "            box_size = 24\n",
    "            rect = plt.Rectangle((x_center - box_size//2, y_center - box_size//2), \n",
    "                              box_size, box_size, \n",
    "                              linewidth=2, edgecolor='r', facecolor='none')\n",
    "            axes[i].add_patch(rect)\n",
    "            axes[i].set_title(f\"Motor Slice (z={z})\", color='red')\n",
    "        \n",
    "        axes[i].axis('on')\n",
    "        axes[i].set_xticks([])\n",
    "        axes[i].set_yticks([])\n",
    "    \n",
    "    plt.suptitle(f\"Tomogram: {tomo_id}, Motor at: z={z_center}, y={y_center}, x={x_center}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize a few detections\n",
    "n_visualize = min(3, len(submission))\n",
    "for i in range(n_visualize):\n",
    "    row = submission.iloc[i]\n",
    "    if row['Motor axis 0'] != -1:  # Only visualize positive detections\n",
    "        visualize_detection(\n",
    "            row['tomo_id'],\n",
    "            {\n",
    "                'Motor axis 0': row['Motor axis 0'],\n",
    "                'Motor axis 1': row['Motor axis 1'],\n",
    "                'Motor axis 2': row['Motor axis 2']\n",
    "            },\n",
    "            TEST_DIR,\n",
    "            context_slices=2\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11294684,
     "sourceId": 91249,
     "sourceType": "competition"
    },
    {
     "datasetId": 7206260,
     "sourceId": 11495557,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7206328,
     "sourceId": 11697608,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
